{"version":3,"file":"web.js","names":["message: BaseMessage","humanPrompt: string","aiPrompt: string","messages: BaseMessage[]","provider: string","tools: BedrockChatCallOptions[\"tools\"]","fields?: BedrockChatFields","options?: this[\"ParsedCallOptions\"]","options: this[\"ParsedCallOptions\"]","options: Partial<this[\"ParsedCallOptions\"]>","runManager?: CallbackManagerForLLMRun","finalResult: ChatGenerationChunk | undefined","_runManager?: CallbackManagerForLLMRun","fields: {\n      bedrockMethod: \"invoke\" | \"invoke-with-response-stream\";\n      endpointHost: string;\n      provider: string;\n    }","chunk","reader: any","a: Uint8Array","b: Uint8Array","buffer: Uint8Array","chunk: Uint8Array","tools: BedrockChatToolType[]","_kwargs?: Partial<this[\"ParsedCallOptions\"]>","x?: ChatGenerationChunk | ChatGeneration","model: string","modelId: string"],"sources":["../../../src/chat_models/bedrock/web.ts"],"sourcesContent":["import { SignatureV4 } from \"@smithy/signature-v4\";\nimport { HttpRequest } from \"@smithy/protocol-http\";\nimport { EventStreamCodec } from \"@smithy/eventstream-codec\";\nimport { fromUtf8, toUtf8 } from \"@smithy/util-utf8\";\nimport { Sha256 } from \"@aws-crypto/sha256-js\";\n\nimport { CallbackManagerForLLMRun } from \"@langchain/core/callbacks/manager\";\nimport {\n  type BaseChatModelParams,\n  BaseChatModel,\n  LangSmithParams,\n  BaseChatModelCallOptions,\n  BindToolsInput,\n} from \"@langchain/core/language_models/chat_models\";\nimport {\n  BaseLanguageModelInput,\n  isOpenAITool,\n} from \"@langchain/core/language_models/base\";\nimport { Runnable } from \"@langchain/core/runnables\";\nimport { getEnvironmentVariable } from \"@langchain/core/utils/env\";\nimport {\n  AIMessageChunk,\n  BaseMessage,\n  AIMessage,\n  ChatMessage,\n  BaseMessageChunk,\n  isAIMessage,\n} from \"@langchain/core/messages\";\nimport {\n  ChatGeneration,\n  ChatGenerationChunk,\n  ChatResult,\n} from \"@langchain/core/outputs\";\nimport {\n  isLangChainTool,\n  isStructuredTool,\n} from \"@langchain/core/utils/function_calling\";\nimport { toJsonSchema } from \"@langchain/core/utils/json_schema\";\nimport { isInteropZodSchema } from \"@langchain/core/utils/types\";\nimport type { SerializedFields } from \"../../load/map_keys.js\";\nimport {\n  BaseBedrockInput,\n  BedrockLLMInputOutputAdapter,\n  type CredentialType,\n} from \"../../utils/bedrock/index.js\";\nimport {\n  _toolsInParams,\n  isAnthropicTool,\n} from \"../../utils/bedrock/anthropic.js\";\n\ntype AnthropicTool = Record<string, unknown>;\n\ntype BedrockChatToolType = BindToolsInput | AnthropicTool;\n\n/**\n * @see https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html#Concepts.RegionsAndAvailabilityZones.Regions\n */\nconst AWS_REGIONS = [\n  \"us\",\n  \"sa\",\n  \"me\",\n  \"mx\",\n  \"il\",\n  \"eu\",\n  \"cn\",\n  \"ca\",\n  \"ap\",\n  \"af\",\n  \"us-gov\",\n  \"apac\",\n];\n\nconst ALLOWED_MODEL_PROVIDERS = [\n  \"ai21\",\n  \"anthropic\",\n  \"amazon\",\n  \"cohere\",\n  \"meta\",\n  \"mistral\",\n  \"deepseek\",\n];\n\nconst PRELUDE_TOTAL_LENGTH_BYTES = 4;\n\nfunction convertOneMessageToText(\n  message: BaseMessage,\n  humanPrompt: string,\n  aiPrompt: string\n): string {\n  if (message._getType() === \"human\") {\n    return `${humanPrompt} ${message.content}`;\n  } else if (message._getType() === \"ai\") {\n    return `${aiPrompt} ${message.content}`;\n  } else if (message._getType() === \"system\") {\n    return `${humanPrompt} <admin>${message.content}</admin>`;\n  } else if (message._getType() === \"function\") {\n    return `${humanPrompt} ${message.content}`;\n  } else if (ChatMessage.isInstance(message)) {\n    return `\\n\\n${\n      message.role[0].toUpperCase() + message.role.slice(1)\n    }: {message.content}`;\n  }\n  throw new Error(`Unknown role: ${message._getType()}`);\n}\n\nexport function convertMessagesToPromptAnthropic(\n  messages: BaseMessage[],\n  humanPrompt = \"\\n\\nHuman:\",\n  aiPrompt = \"\\n\\nAssistant:\"\n): string {\n  const messagesCopy = [...messages];\n\n  if (\n    messagesCopy.length === 0 ||\n    messagesCopy[messagesCopy.length - 1]._getType() !== \"ai\"\n  ) {\n    messagesCopy.push(new AIMessage({ content: \"\" }));\n  }\n\n  return messagesCopy\n    .map((message) => convertOneMessageToText(message, humanPrompt, aiPrompt))\n    .join(\"\");\n}\n\n/**\n * Function that converts an array of messages into a single string prompt\n * that can be used as input for a chat model. It delegates the conversion\n * logic to the appropriate provider-specific function.\n * @param messages Array of messages to be converted.\n * @param options Options to be used during the conversion.\n * @returns A string prompt that can be used as input for a chat model.\n */\nexport function convertMessagesToPrompt(\n  messages: BaseMessage[],\n  provider: string\n): string {\n  if (provider === \"anthropic\") {\n    return convertMessagesToPromptAnthropic(messages);\n  }\n  throw new Error(`Provider ${provider} does not support chat.`);\n}\n\nfunction formatTools(tools: BedrockChatCallOptions[\"tools\"]): AnthropicTool[] {\n  if (!tools || !tools.length) {\n    return [];\n  }\n  if (tools.every(isLangChainTool)) {\n    return tools.map((tc) => ({\n      name: tc.name,\n      description: tc.description,\n      input_schema: isInteropZodSchema(tc.schema)\n        ? toJsonSchema(tc.schema)\n        : tc.schema,\n    }));\n  }\n  if (tools.every(isOpenAITool)) {\n    return tools.map((tc) => ({\n      name: tc.function.name,\n      description: tc.function.description,\n      input_schema: tc.function.parameters,\n    }));\n  }\n  if (tools.every(isAnthropicTool)) {\n    return tools;\n  }\n  if (\n    tools.some(isStructuredTool) ||\n    tools.some(isOpenAITool) ||\n    tools.some(isAnthropicTool)\n  ) {\n    throw new Error(\n      \"All tools passed to BedrockChat must be of the same type.\"\n    );\n  }\n  throw new Error(\"Invalid tool format received.\");\n}\n\nexport interface BedrockChatCallOptions extends BaseChatModelCallOptions {\n  tools?: BedrockChatToolType[];\n}\n\nexport interface BedrockChatFields\n  extends Partial<BaseBedrockInput>, BaseChatModelParams {}\n\n/**\n * AWS Bedrock chat model integration.\n *\n * Setup:\n * Install `@langchain/community` and set the following environment variables:\n *\n * ```bash\n * npm install @langchain/openai\n * export AWS_REGION=\"your-aws-region\"\n * export AWS_SECRET_ACCESS_KEY=\"your-aws-secret-access-key\"\n * export AWS_ACCESS_KEY_ID=\"your-aws-access-key-id\"\n * ```\n *\n * ## [Constructor args](/classes/langchain_community_chat_models_bedrock.BedrockChat.html#constructor)\n *\n * ## [Runtime args](/interfaces/langchain_community_chat_models_bedrock_web.BedrockChatCallOptions.html)\n *\n * Runtime args can be passed as the second argument to any of the base runnable methods `.invoke`. `.stream`, `.batch`, etc.\n * They can also be passed via `.withConfig`, or the second arg in `.bindTools`, like shown in the examples below:\n *\n * ```typescript\n * // When calling `.withConfig`, call options should be passed via the first argument\n * const llmWithArgsBound = llm.withConfig({\n *   stop: [\"\\n\"],\n *   tools: [...],\n * });\n *\n * // When calling `.bindTools`, call options should be passed via the second argument\n * const llmWithTools = llm.bindTools(\n *   [...],\n *   {\n *     stop: [\"stop on this token!\"],\n *   }\n * );\n * ```\n *\n * ## Examples\n *\n * <details open>\n * <summary><strong>Instantiate</strong></summary>\n *\n * ```typescript\n * import { BedrockChat } from '@langchain/community/chat_models/bedrock/web';\n *\n * const llm = new BedrockChat({\n *   region: process.env.AWS_REGION,\n *   maxRetries: 0,\n *   model: \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n *   temperature: 0,\n *   maxTokens: undefined,\n *   // other params...\n * });\n *\n * // You can also pass credentials in explicitly:\n * const llmWithCredentials = new BedrockChat({\n *   region: process.env.BEDROCK_AWS_REGION,\n *   model: \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n *   credentials: {\n *     secretAccessKey: process.env.BEDROCK_AWS_SECRET_ACCESS_KEY!,\n *     accessKeyId: process.env.BEDROCK_AWS_ACCESS_KEY_ID!,\n *   },\n * });\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Invoking</strong></summary>\n *\n * ```typescript\n * const input = `Translate \"I love programming\" into French.`;\n *\n * // Models also accept a list of chat messages or a formatted prompt\n * const result = await llm.invoke(input);\n * console.log(result);\n * ```\n *\n * ```txt\n * AIMessage {\n *   \"content\": \"Here's the translation to French:\\n\\nJ'adore la programmation.\",\n *   \"additional_kwargs\": {\n *     \"id\": \"msg_bdrk_01HCZHa2mKbMZeTeHjLDd286\"\n *   },\n *   \"response_metadata\": {\n *     \"type\": \"message\",\n *     \"role\": \"assistant\",\n *     \"model\": \"claude-3-5-sonnet-20240620\",\n *     \"stop_reason\": \"end_turn\",\n *     \"stop_sequence\": null,\n *     \"usage\": {\n *       \"input_tokens\": 25,\n *       \"output_tokens\": 19\n *     }\n *   },\n *   \"tool_calls\": [],\n *   \"invalid_tool_calls\": []\n * }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Streaming Chunks</strong></summary>\n *\n * ```typescript\n * for await (const chunk of await llm.stream(input)) {\n *   console.log(chunk);\n * }\n * ```\n *\n * ```txt\n * AIMessageChunk {\n *   \"content\": \"\",\n *   \"additional_kwargs\": {\n *     \"id\": \"msg_bdrk_01RhFuGR9uJ2bj5GbdAma4y6\"\n *   },\n *   \"response_metadata\": {\n *     \"type\": \"message\",\n *     \"role\": \"assistant\",\n *     \"model\": \"claude-3-5-sonnet-20240620\",\n *     \"stop_reason\": null,\n *     \"stop_sequence\": null\n *   },\n * }\n * AIMessageChunk {\n *   \"content\": \"J\",\n * }\n * AIMessageChunk {\n *   \"content\": \"'adore la\",\n * }\n * AIMessageChunk {\n *   \"content\": \" programmation.\",\n * }\n * AIMessageChunk {\n *   \"content\": \"\",\n *   \"additional_kwargs\": {\n *     \"stop_reason\": \"end_turn\",\n *     \"stop_sequence\": null\n *   },\n * }\n * AIMessageChunk {\n *   \"content\": \"\",\n *   \"response_metadata\": {\n *     \"amazon-bedrock-invocationMetrics\": {\n *       \"inputTokenCount\": 25,\n *       \"outputTokenCount\": 11,\n *       \"invocationLatency\": 659,\n *       \"firstByteLatency\": 506\n *     }\n *   },\n *   \"usage_metadata\": {\n *     \"input_tokens\": 25,\n *     \"output_tokens\": 11,\n *     \"total_tokens\": 36\n *   }\n * }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Aggregate Streamed Chunks</strong></summary>\n *\n * ```typescript\n * import { AIMessageChunk } from '@langchain/core/messages';\n * import { concat } from '@langchain/core/utils/stream';\n *\n * const stream = await llm.stream(input);\n * let full: AIMessageChunk | undefined;\n * for await (const chunk of stream) {\n *   full = !full ? chunk : concat(full, chunk);\n * }\n * console.log(full);\n * ```\n *\n * ```txt\n * AIMessageChunk {\n *   \"content\": \"J'adore la programmation.\",\n *   \"additional_kwargs\": {\n *     \"id\": \"msg_bdrk_017b6PuBybA51P5LZ9K6gZHm\",\n *     \"stop_reason\": \"end_turn\",\n *     \"stop_sequence\": null\n *   },\n *   \"response_metadata\": {\n *     \"type\": \"message\",\n *     \"role\": \"assistant\",\n *     \"model\": \"claude-3-5-sonnet-20240620\",\n *     \"stop_reason\": null,\n *     \"stop_sequence\": null,\n *     \"amazon-bedrock-invocationMetrics\": {\n *       \"inputTokenCount\": 25,\n *       \"outputTokenCount\": 11,\n *       \"invocationLatency\": 1181,\n *       \"firstByteLatency\": 1177\n *     }\n *   },\n *   \"usage_metadata\": {\n *     \"input_tokens\": 25,\n *     \"output_tokens\": 11,\n *     \"total_tokens\": 36\n *   }\n * }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Bind tools</strong></summary>\n *\n * ```typescript\n * import { z } from 'zod';\n * import { AIMessage } from '@langchain/core/messages';\n *\n * const GetWeather = {\n *   name: \"GetWeather\",\n *   description: \"Get the current weather in a given location\",\n *   schema: z.object({\n *     location: z.string().describe(\"The city and state, e.g. San Francisco, CA\")\n *   }),\n * }\n *\n * const GetPopulation = {\n *   name: \"GetPopulation\",\n *   description: \"Get the current population in a given location\",\n *   schema: z.object({\n *     location: z.string().describe(\"The city and state, e.g. San Francisco, CA\")\n *   }),\n * }\n *\n * const llmWithTools = llm.bindTools([GetWeather, GetPopulation]);\n * const aiMsg: AIMessage = await llmWithTools.invoke(\n *   \"Which city is hotter today and which is bigger: LA or NY?\"\n * );\n * console.log(aiMsg.tool_calls);\n * ```\n *\n * ```txt\n * [\n *   {\n *     name: 'GetWeather',\n *     args: { location: 'Los Angeles, CA' },\n *     id: 'toolu_bdrk_01R2daqwHR931r4baVNzbe38',\n *     type: 'tool_call'\n *   },\n *   {\n *     name: 'GetWeather',\n *     args: { location: 'New York, NY' },\n *     id: 'toolu_bdrk_01WDadwNc7PGqVZvCN7Dr7eD',\n *     type: 'tool_call'\n *   },\n *   {\n *     name: 'GetPopulation',\n *     args: { location: 'Los Angeles, CA' },\n *     id: 'toolu_bdrk_014b8zLkpAgpxrPfewKinJFc',\n *     type: 'tool_call'\n *   },\n *   {\n *     name: 'GetPopulation',\n *     args: { location: 'New York, NY' },\n *     id: 'toolu_bdrk_01Tt8K2MUP15kNuMDFCLEFKN',\n *     type: 'tool_call'\n *   }\n * ]\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Structured Output</strong></summary>\n *\n * ```typescript\n * const Joke = z.object({\n *   setup: z.string().describe(\"The setup of the joke\"),\n *   punchline: z.string().describe(\"The punchline to the joke\"),\n *   rating: z.number().optional().describe(\"How funny the joke is, from 1 to 10\")\n * }).describe('Joke to tell user.');\n *\n * const structuredLlm = llm.withStructuredOutput(Joke);\n * const jokeResult = await structuredLlm.invoke(\"Tell me a joke about cats\");\n * console.log(jokeResult);\n * ```\n *\n * ```txt\n * {\n *   setup: \"Why don't cats play poker in the jungle?\",\n *   punchline: 'Too many cheetahs!'\n * }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Response Metadata</strong></summary>\n *\n * ```typescript\n * const aiMsgForResponseMetadata = await llm.invoke(input);\n * console.log(aiMsgForResponseMetadata.response_metadata);\n * ```\n *\n * ```txt\n * \"response_metadata\": {\n *   \"type\": \"message\",\n *   \"role\": \"assistant\",\n *   \"model\": \"claude-3-5-sonnet-20240620\",\n *   \"stop_reason\": \"end_turn\",\n *   \"stop_sequence\": null,\n *   \"usage\": {\n *     \"input_tokens\": 25,\n *     \"output_tokens\": 19\n *   }\n * }\n * ```\n * </details>\n */\nexport class BedrockChat\n  extends BaseChatModel<BedrockChatCallOptions, AIMessageChunk>\n  implements BaseBedrockInput\n{\n  model = \"amazon.titan-tg1-large\";\n\n  modelProvider: string;\n\n  region: string;\n\n  credentials: CredentialType;\n\n  temperature?: number | undefined = undefined;\n\n  maxTokens?: number | undefined = undefined;\n\n  fetchFn: typeof fetch;\n\n  endpointHost?: string;\n\n  modelKwargs?: Record<string, unknown>;\n\n  codec: EventStreamCodec = new EventStreamCodec(toUtf8, fromUtf8);\n\n  streaming = false;\n\n  usesMessagesApi = false;\n\n  lc_serializable = true;\n\n  trace?: \"ENABLED\" | \"DISABLED\";\n\n  guardrailIdentifier = \"\";\n\n  guardrailVersion = \"\";\n\n  guardrailConfig?: {\n    tagSuffix: string;\n    streamProcessingMode: \"SYNCHRONOUS\" | \"ASYNCHRONOUS\";\n  };\n\n  get lc_aliases(): Record<string, string> {\n    return {\n      model: \"model_id\",\n      region: \"region_name\",\n    };\n  }\n\n  get lc_secrets(): { [key: string]: string } | undefined {\n    return {\n      \"credentials.accessKeyId\": \"AWS_ACCESS_KEY_ID\",\n      \"credentials.secretAccessKey\": \"AWS_SECRET_ACCESS_KEY\",\n      \"credentials.sessionToken\": \"AWS_SECRET_ACCESS_KEY\",\n      awsAccessKeyId: \"AWS_ACCESS_KEY_ID\",\n      awsSecretAccessKey: \"AWS_SECRET_ACCESS_KEY\",\n      awsSessionToken: \"AWS_SESSION_TOKEN\",\n    };\n  }\n\n  get lc_attributes(): SerializedFields | undefined {\n    return { region: this.region };\n  }\n\n  _identifyingParams(): Record<string, string> {\n    return {\n      model: this.model,\n    };\n  }\n\n  _llmType() {\n    return \"bedrock\";\n  }\n\n  static lc_name() {\n    return \"BedrockChat\";\n  }\n\n  constructor(fields?: BedrockChatFields) {\n    const awsAccessKeyId =\n      fields?.awsAccessKeyId ?? getEnvironmentVariable(\"AWS_ACCESS_KEY_ID\");\n    const awsSecretAccessKey =\n      fields?.awsSecretAccessKey ??\n      getEnvironmentVariable(\"AWS_SECRET_ACCESS_KEY\");\n    const awsSessionToken =\n      fields?.awsSessionToken ?? getEnvironmentVariable(\"AWS_SESSION_TOKEN\");\n\n    let credentials = fields?.credentials;\n    if (credentials === undefined) {\n      if (awsAccessKeyId === undefined || awsSecretAccessKey === undefined) {\n        throw new Error(\n          \"Please set your AWS credentials in the 'credentials' field or set env vars AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY, and optionally AWS_SESSION_TOKEN.\"\n        );\n      }\n      credentials = {\n        accessKeyId: awsAccessKeyId,\n        secretAccessKey: awsSecretAccessKey,\n        sessionToken: awsSessionToken,\n      };\n    }\n\n    // eslint-disable-next-line no-param-reassign\n    fields = { ...fields, awsAccessKeyId, awsSecretAccessKey, awsSessionToken };\n\n    super(fields);\n\n    this.model = fields?.model ?? this.model;\n    this.modelProvider = getModelProvider(this.model);\n\n    if (!ALLOWED_MODEL_PROVIDERS.includes(this.modelProvider)) {\n      throw new Error(\n        `Unknown model provider: '${this.modelProvider}', only these are supported: ${ALLOWED_MODEL_PROVIDERS}`\n      );\n    }\n    const region =\n      fields?.region ?? getEnvironmentVariable(\"AWS_DEFAULT_REGION\");\n    if (!region) {\n      throw new Error(\n        \"Please set the AWS_DEFAULT_REGION environment variable or pass it to the constructor as the region field.\"\n      );\n    }\n    this.region = region;\n\n    this.credentials = credentials;\n\n    this.temperature = fields?.temperature ?? this.temperature;\n    this.maxTokens = fields?.maxTokens ?? this.maxTokens;\n    this.fetchFn = fields?.fetchFn ?? fetch.bind(globalThis);\n    this.endpointHost = fields?.endpointHost ?? fields?.endpointUrl;\n    this.modelKwargs = fields?.modelKwargs;\n    this.streaming = fields?.streaming ?? this.streaming;\n    this.usesMessagesApi = canUseMessagesApi(this.model);\n    this.trace = fields?.trace ?? this.trace;\n    this.guardrailVersion = fields?.guardrailVersion ?? this.guardrailVersion;\n    this.guardrailIdentifier =\n      fields?.guardrailIdentifier ?? this.guardrailIdentifier;\n    this.guardrailConfig = fields?.guardrailConfig;\n    // Permit Application Inference Profile override in fetch URL (expects to be url-encoded)\n    if (fields?.applicationInferenceProfile) {\n      this.model = fields?.applicationInferenceProfile;\n    }\n  }\n\n  override invocationParams(options?: this[\"ParsedCallOptions\"]) {\n    if (options?.tool_choice) {\n      throw new Error(\n        \"'tool_choice' call option is not supported by BedrockChat.\"\n      );\n    }\n\n    return {\n      tools: options?.tools ? formatTools(options.tools) : undefined,\n      temperature: this.temperature,\n      max_tokens: this.maxTokens,\n      stop: options?.stop,\n      modelKwargs: this.modelKwargs,\n      guardrailConfig: this.guardrailConfig,\n    };\n  }\n\n  getLsParams(options: this[\"ParsedCallOptions\"]): LangSmithParams {\n    const params = this.invocationParams(options);\n    return {\n      ls_provider: \"bedrock\",\n      ls_model_name: this.model,\n      ls_model_type: \"chat\",\n      ls_temperature: params.temperature ?? undefined,\n      ls_max_tokens: params.max_tokens ?? undefined,\n      ls_stop: options.stop,\n    };\n  }\n\n  async _generate(\n    messages: BaseMessage[],\n    options: Partial<this[\"ParsedCallOptions\"]>,\n    runManager?: CallbackManagerForLLMRun\n  ): Promise<ChatResult> {\n    if (this.streaming) {\n      const stream = this._streamResponseChunks(messages, options, runManager);\n      let finalResult: ChatGenerationChunk | undefined;\n      for await (const chunk of stream) {\n        if (finalResult === undefined) {\n          finalResult = chunk;\n        } else {\n          finalResult = finalResult.concat(chunk);\n        }\n      }\n      if (finalResult === undefined) {\n        throw new Error(\n          \"Could not parse final output from Bedrock streaming call.\"\n        );\n      }\n      return {\n        generations: [finalResult],\n        llmOutput: finalResult.generationInfo,\n      };\n    }\n    return this._generateNonStreaming(messages, options, runManager);\n  }\n\n  async _generateNonStreaming(\n    messages: BaseMessage[],\n    options: Partial<this[\"ParsedCallOptions\"]>,\n    _runManager?: CallbackManagerForLLMRun\n  ): Promise<ChatResult> {\n    const service = \"bedrock-runtime\";\n    const endpointHost =\n      this.endpointHost ?? `${service}.${this.region}.amazonaws.com`;\n    const provider = this.modelProvider;\n    const response = await this._signedFetch(messages, options, {\n      bedrockMethod: \"invoke\",\n      endpointHost,\n      provider,\n    });\n    const json = await response.json();\n    if (!response.ok) {\n      throw new Error(\n        `Error ${response.status}: ${json.message ?? JSON.stringify(json)}`\n      );\n    }\n    if (this.usesMessagesApi) {\n      const outputGeneration =\n        BedrockLLMInputOutputAdapter.prepareMessagesOutput(provider, json);\n      if (outputGeneration === undefined) {\n        throw new Error(\"Failed to parse output generation.\");\n      }\n      return {\n        generations: [outputGeneration],\n        llmOutput: outputGeneration.generationInfo,\n      };\n    } else {\n      const text = BedrockLLMInputOutputAdapter.prepareOutput(provider, json);\n      return { generations: [{ text, message: new AIMessage(text) }] };\n    }\n  }\n\n  async _signedFetch(\n    messages: BaseMessage[],\n    options: this[\"ParsedCallOptions\"],\n    fields: {\n      bedrockMethod: \"invoke\" | \"invoke-with-response-stream\";\n      endpointHost: string;\n      provider: string;\n    }\n  ) {\n    const { bedrockMethod, endpointHost, provider } = fields;\n    const {\n      max_tokens,\n      temperature,\n      stop,\n      modelKwargs,\n      guardrailConfig,\n      tools,\n    } = this.invocationParams(options);\n    const inputBody = this.usesMessagesApi\n      ? BedrockLLMInputOutputAdapter.prepareMessagesInput(\n          provider,\n          messages,\n          max_tokens,\n          temperature,\n          stop,\n          modelKwargs,\n          guardrailConfig,\n          tools\n        )\n      : BedrockLLMInputOutputAdapter.prepareInput(\n          provider,\n          convertMessagesToPromptAnthropic(messages),\n          max_tokens,\n          temperature,\n          stop,\n          modelKwargs,\n          fields.bedrockMethod,\n          guardrailConfig\n        );\n\n    const url = new URL(\n      `https://${endpointHost}/model/${this.model}/${bedrockMethod}`\n    );\n\n    const request = new HttpRequest({\n      hostname: url.hostname,\n      path: url.pathname,\n      protocol: url.protocol,\n      method: \"POST\", // method must be uppercase\n      body: JSON.stringify(inputBody),\n      query: Object.fromEntries(url.searchParams.entries()),\n      headers: {\n        // host is required by AWS Signature V4: https://docs.aws.amazon.com/general/latest/gr/sigv4-create-canonical-request.html\n        host: url.host,\n        accept: \"application/json\",\n        \"content-type\": \"application/json\",\n        ...(this.trace &&\n          this.guardrailIdentifier &&\n          this.guardrailVersion && {\n            \"X-Amzn-Bedrock-Trace\": this.trace,\n            \"X-Amzn-Bedrock-GuardrailIdentifier\": this.guardrailIdentifier,\n            \"X-Amzn-Bedrock-GuardrailVersion\": this.guardrailVersion,\n          }),\n      },\n    });\n\n    const signer = new SignatureV4({\n      credentials: this.credentials,\n      service: \"bedrock\",\n      region: this.region,\n      sha256: Sha256,\n    });\n\n    const signedRequest = await signer.sign(request);\n\n    // Send request to AWS using the low-level fetch API\n    const response = await this.caller.callWithOptions(\n      { signal: options.signal },\n      async () =>\n        this.fetchFn(url, {\n          headers: signedRequest.headers,\n          body: signedRequest.body,\n          method: signedRequest.method,\n        })\n    );\n    return response;\n  }\n\n  async *_streamResponseChunks(\n    messages: BaseMessage[],\n    options: this[\"ParsedCallOptions\"],\n    runManager?: CallbackManagerForLLMRun\n  ): AsyncGenerator<ChatGenerationChunk> {\n    const provider = this.modelProvider;\n    const service = \"bedrock-runtime\";\n\n    const endpointHost =\n      this.endpointHost ?? `${service}.${this.region}.amazonaws.com`;\n\n    const bedrockMethod =\n      provider === \"anthropic\" ||\n      provider === \"cohere\" ||\n      provider === \"meta\" ||\n      provider === \"mistral\"\n        ? \"invoke-with-response-stream\"\n        : \"invoke\";\n\n    const response = await this._signedFetch(messages, options, {\n      bedrockMethod,\n      endpointHost,\n      provider,\n    });\n\n    if (response.status < 200 || response.status >= 300) {\n      throw Error(\n        `Failed to access underlying url '${endpointHost}': got ${\n          response.status\n        } ${response.statusText}: ${await response.text()}`\n      );\n    }\n\n    if (\n      provider === \"anthropic\" ||\n      provider === \"cohere\" ||\n      provider === \"meta\" ||\n      provider === \"mistral\"\n    ) {\n      const toolsInParams = _toolsInParams(options);\n      const reader = response.body?.getReader();\n      const decoder = new TextDecoder();\n      for await (const chunk of this._readChunks(reader)) {\n        const event = this.codec.decode(chunk);\n        if (\n          (event.headers[\":event-type\"] !== undefined &&\n            event.headers[\":event-type\"].value !== \"chunk\") ||\n          event.headers[\":content-type\"].value !== \"application/json\"\n        ) {\n          throw Error(`Failed to get event chunk: got ${chunk}`);\n        }\n        const body = JSON.parse(decoder.decode(event.body));\n        if (body.message) {\n          throw new Error(body.message);\n        }\n        if (body.bytes !== undefined) {\n          const chunkResult = JSON.parse(\n            decoder.decode(\n              Uint8Array.from(atob(body.bytes), (m) => m.codePointAt(0) ?? 0)\n            )\n          );\n          if (this.usesMessagesApi) {\n            const chunk = BedrockLLMInputOutputAdapter.prepareMessagesOutput(\n              provider,\n              chunkResult,\n              {\n                // Content should _ONLY_ be coerced if tools are not in params\n                // If they are, we need content to be of type MessageTypeComplex\n                // so the tools can be passed through.\n                coerceContentToString: !toolsInParams,\n              }\n            );\n            if (chunk === undefined) {\n              continue;\n            }\n            if (\n              provider === \"anthropic\" &&\n              chunk.generationInfo?.usage !== undefined\n            ) {\n              // Avoid bad aggregation in chunks, rely on final Bedrock data\n              delete chunk.generationInfo.usage;\n            }\n            const finalMetrics =\n              chunk.generationInfo?.[\"amazon-bedrock-invocationMetrics\"];\n            if (\n              finalMetrics != null &&\n              typeof finalMetrics === \"object\" &&\n              isAIMessage(chunk.message)\n            ) {\n              chunk.message.usage_metadata = {\n                input_tokens: finalMetrics.inputTokenCount,\n                output_tokens: finalMetrics.outputTokenCount,\n                total_tokens:\n                  finalMetrics.inputTokenCount + finalMetrics.outputTokenCount,\n              };\n            }\n            if (isChatGenerationChunk(chunk)) {\n              yield chunk;\n              // eslint-disable-next-line no-void\n              void runManager?.handleLLMNewToken(\n                chunk.text,\n                undefined,\n                undefined,\n                undefined,\n                undefined,\n                {\n                  chunk,\n                }\n              );\n            } else {\n              // eslint-disable-next-line no-void\n              void runManager?.handleLLMNewToken(chunk.text);\n            }\n          } else {\n            const text = BedrockLLMInputOutputAdapter.prepareOutput(\n              provider,\n              chunkResult\n            );\n            const chunk = new ChatGenerationChunk({\n              text,\n              message: new AIMessageChunk({ content: text }),\n            });\n            yield chunk;\n            // eslint-disable-next-line no-void\n            void runManager?.handleLLMNewToken(\n              text,\n              undefined,\n              undefined,\n              undefined,\n              undefined,\n              { chunk }\n            );\n          }\n        }\n      }\n    } else {\n      const json = await response.json();\n      const text = BedrockLLMInputOutputAdapter.prepareOutput(provider, json);\n      yield new ChatGenerationChunk({\n        text,\n        message: new AIMessageChunk({ content: text }),\n      });\n      // eslint-disable-next-line no-void\n      void runManager?.handleLLMNewToken(text);\n    }\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  _readChunks(reader: any) {\n    function _concatChunks(a: Uint8Array, b: Uint8Array) {\n      const newBuffer = new Uint8Array(a.length + b.length);\n      newBuffer.set(a);\n      newBuffer.set(b, a.length);\n      return newBuffer;\n    }\n\n    function getMessageLength(buffer: Uint8Array) {\n      if (buffer.byteLength < PRELUDE_TOTAL_LENGTH_BYTES) return 0;\n      const view = new DataView(\n        buffer.buffer,\n        buffer.byteOffset,\n        buffer.byteLength\n      );\n\n      return view.getUint32(0, false);\n    }\n\n    return {\n      async *[Symbol.asyncIterator]() {\n        let readResult = await reader.read();\n\n        let buffer: Uint8Array = new Uint8Array(0);\n        while (!readResult.done) {\n          const chunk: Uint8Array = readResult.value;\n\n          buffer = _concatChunks(buffer, chunk);\n          let messageLength = getMessageLength(buffer);\n\n          while (\n            buffer.byteLength >= PRELUDE_TOTAL_LENGTH_BYTES &&\n            buffer.byteLength >= messageLength\n          ) {\n            yield buffer.slice(0, messageLength);\n            buffer = buffer.slice(messageLength);\n            messageLength = getMessageLength(buffer);\n          }\n\n          readResult = await reader.read();\n        }\n      },\n    };\n  }\n\n  _combineLLMOutput() {\n    return {};\n  }\n\n  override bindTools(\n    tools: BedrockChatToolType[],\n    _kwargs?: Partial<this[\"ParsedCallOptions\"]>\n  ): Runnable<\n    BaseLanguageModelInput,\n    BaseMessageChunk,\n    this[\"ParsedCallOptions\"]\n  > {\n    const provider = this.modelProvider;\n    if (provider !== \"anthropic\") {\n      throw new Error(\n        \"Currently, tool calling through Bedrock is only supported for Anthropic models.\"\n      );\n    }\n    return this.withConfig({\n      tools: formatTools(tools),\n    });\n  }\n}\n\nfunction isChatGenerationChunk(\n  x?: ChatGenerationChunk | ChatGeneration\n): x is ChatGenerationChunk {\n  return (\n    x !== undefined && typeof (x as ChatGenerationChunk).concat === \"function\"\n  );\n}\n\nfunction canUseMessagesApi(model: string): boolean {\n  const modelProviderName = getModelProvider(model);\n\n  if (\n    modelProviderName === \"anthropic\" &&\n    !model.includes(\"claude-v2\") &&\n    !model.includes(\"claude-instant-v1\")\n  ) {\n    return true;\n  }\n\n  if (modelProviderName === \"cohere\") {\n    if (model.includes(\"command-r-v1\")) {\n      return true;\n    }\n    if (model.includes(\"command-r-plus-v1\")) {\n      return true;\n    }\n  }\n\n  return false;\n}\n\nfunction isInferenceModel(modelId: string): boolean {\n  const parts = modelId.split(\".\");\n  return AWS_REGIONS.some((region) => parts[0] === region);\n}\n\nfunction getModelProvider(modelId: string): string {\n  const parts = modelId.split(\".\");\n  if (isInferenceModel(modelId)) {\n    return parts[1];\n  } else {\n    return parts[0];\n  }\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;AAyDA,MAAM,cAAc;CAClB;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;AACD;AAED,MAAM,0BAA0B;CAC9B;CACA;CACA;CACA;CACA;CACA;CACA;AACD;AAED,MAAM,6BAA6B;AAEnC,SAAS,wBACPA,SACAC,aACAC,UACQ;AACR,KAAI,QAAQ,UAAU,KAAK,QACzB,QAAO,GAAG,YAAY,CAAC,EAAE,QAAQ,SAAS;UACjC,QAAQ,UAAU,KAAK,KAChC,QAAO,GAAG,SAAS,CAAC,EAAE,QAAQ,SAAS;UAC9B,QAAQ,UAAU,KAAK,SAChC,QAAO,GAAG,YAAY,QAAQ,EAAE,QAAQ,QAAQ,QAAQ,CAAC;UAChD,QAAQ,UAAU,KAAK,WAChC,QAAO,GAAG,YAAY,CAAC,EAAE,QAAQ,SAAS;UACjC,YAAY,WAAW,QAAQ,CACxC,QAAO,CAAC,IAAI,EACV,QAAQ,KAAK,GAAG,aAAa,GAAG,QAAQ,KAAK,MAAM,EAAE,CACtD,mBAAmB,CAAC;AAEvB,OAAM,IAAI,MAAM,CAAC,cAAc,EAAE,QAAQ,UAAU,EAAE;AACtD;AAED,SAAgB,iCACdC,UACA,cAAc,cACd,WAAW,kBACH;CACR,MAAM,eAAe,CAAC,GAAG,QAAS;AAElC,KACE,aAAa,WAAW,KACxB,aAAa,aAAa,SAAS,GAAG,UAAU,KAAK,MAErD,aAAa,KAAK,IAAI,UAAU,EAAE,SAAS,GAAI,GAAE;AAGnD,QAAO,aACJ,IAAI,CAAC,YAAY,wBAAwB,SAAS,aAAa,SAAS,CAAC,CACzE,KAAK,GAAG;AACZ;;;;;;;;;AAUD,SAAgB,wBACdA,UACAC,UACQ;AACR,KAAI,aAAa,YACf,QAAO,iCAAiC,SAAS;AAEnD,OAAM,IAAI,MAAM,CAAC,SAAS,EAAE,SAAS,uBAAuB,CAAC;AAC9D;AAED,SAAS,YAAYC,OAAyD;AAC5E,KAAI,CAAC,SAAS,CAAC,MAAM,OACnB,QAAO,CAAE;AAEX,KAAI,MAAM,MAAM,gBAAgB,CAC9B,QAAO,MAAM,IAAI,CAAC,QAAQ;EACxB,MAAM,GAAG;EACT,aAAa,GAAG;EAChB,cAAc,mBAAmB,GAAG,OAAO,GACvC,aAAa,GAAG,OAAO,GACvB,GAAG;CACR,GAAE;AAEL,KAAI,MAAM,MAAM,aAAa,CAC3B,QAAO,MAAM,IAAI,CAAC,QAAQ;EACxB,MAAM,GAAG,SAAS;EAClB,aAAa,GAAG,SAAS;EACzB,cAAc,GAAG,SAAS;CAC3B,GAAE;AAEL,KAAI,MAAM,MAAM,gBAAgB,CAC9B,QAAO;AAET,KACE,MAAM,KAAK,iBAAiB,IAC5B,MAAM,KAAK,aAAa,IACxB,MAAM,KAAK,gBAAgB,CAE3B,OAAM,IAAI,MACR;AAGJ,OAAM,IAAI,MAAM;AACjB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAyUD,IAAa,cAAb,cACU,cAEV;CACE,QAAQ;CAER;CAEA;CAEA;CAEA,cAAmC;CAEnC,YAAiC;CAEjC;CAEA;CAEA;CAEA,QAA0B,IAAI,iBAAiB,QAAQ;CAEvD,YAAY;CAEZ,kBAAkB;CAElB,kBAAkB;CAElB;CAEA,sBAAsB;CAEtB,mBAAmB;CAEnB;CAKA,IAAI,aAAqC;AACvC,SAAO;GACL,OAAO;GACP,QAAQ;EACT;CACF;CAED,IAAI,aAAoD;AACtD,SAAO;GACL,2BAA2B;GAC3B,+BAA+B;GAC/B,4BAA4B;GAC5B,gBAAgB;GAChB,oBAAoB;GACpB,iBAAiB;EAClB;CACF;CAED,IAAI,gBAA8C;AAChD,SAAO,EAAE,QAAQ,KAAK,OAAQ;CAC/B;CAED,qBAA6C;AAC3C,SAAO,EACL,OAAO,KAAK,MACb;CACF;CAED,WAAW;AACT,SAAO;CACR;CAED,OAAO,UAAU;AACf,SAAO;CACR;CAED,YAAYC,QAA4B;EACtC,MAAM,iBACJ,QAAQ,kBAAkB,uBAAuB,oBAAoB;EACvE,MAAM,qBACJ,QAAQ,sBACR,uBAAuB,wBAAwB;EACjD,MAAM,kBACJ,QAAQ,mBAAmB,uBAAuB,oBAAoB;EAExE,IAAI,cAAc,QAAQ;AAC1B,MAAI,gBAAgB,QAAW;AAC7B,OAAI,mBAAmB,UAAa,uBAAuB,OACzD,OAAM,IAAI,MACR;GAGJ,cAAc;IACZ,aAAa;IACb,iBAAiB;IACjB,cAAc;GACf;EACF;EAGD,SAAS;GAAE,GAAG;GAAQ;GAAgB;GAAoB;EAAiB;EAE3E,MAAM,OAAO;EAEb,KAAK,QAAQ,QAAQ,SAAS,KAAK;EACnC,KAAK,gBAAgB,iBAAiB,KAAK,MAAM;AAEjD,MAAI,CAAC,wBAAwB,SAAS,KAAK,cAAc,CACvD,OAAM,IAAI,MACR,CAAC,yBAAyB,EAAE,KAAK,cAAc,6BAA6B,EAAE,yBAAyB;EAG3G,MAAM,SACJ,QAAQ,UAAU,uBAAuB,qBAAqB;AAChE,MAAI,CAAC,OACH,OAAM,IAAI,MACR;EAGJ,KAAK,SAAS;EAEd,KAAK,cAAc;EAEnB,KAAK,cAAc,QAAQ,eAAe,KAAK;EAC/C,KAAK,YAAY,QAAQ,aAAa,KAAK;EAC3C,KAAK,UAAU,QAAQ,WAAW,MAAM,KAAK,WAAW;EACxD,KAAK,eAAe,QAAQ,gBAAgB,QAAQ;EACpD,KAAK,cAAc,QAAQ;EAC3B,KAAK,YAAY,QAAQ,aAAa,KAAK;EAC3C,KAAK,kBAAkB,kBAAkB,KAAK,MAAM;EACpD,KAAK,QAAQ,QAAQ,SAAS,KAAK;EACnC,KAAK,mBAAmB,QAAQ,oBAAoB,KAAK;EACzD,KAAK,sBACH,QAAQ,uBAAuB,KAAK;EACtC,KAAK,kBAAkB,QAAQ;AAE/B,MAAI,QAAQ,6BACV,KAAK,QAAQ,QAAQ;CAExB;CAED,AAAS,iBAAiBC,SAAqC;AAC7D,MAAI,SAAS,YACX,OAAM,IAAI,MACR;AAIJ,SAAO;GACL,OAAO,SAAS,QAAQ,YAAY,QAAQ,MAAM,GAAG;GACrD,aAAa,KAAK;GAClB,YAAY,KAAK;GACjB,MAAM,SAAS;GACf,aAAa,KAAK;GAClB,iBAAiB,KAAK;EACvB;CACF;CAED,YAAYC,SAAqD;EAC/D,MAAM,SAAS,KAAK,iBAAiB,QAAQ;AAC7C,SAAO;GACL,aAAa;GACb,eAAe,KAAK;GACpB,eAAe;GACf,gBAAgB,OAAO,eAAe;GACtC,eAAe,OAAO,cAAc;GACpC,SAAS,QAAQ;EAClB;CACF;CAED,MAAM,UACJL,UACAM,SACAC,YACqB;AACrB,MAAI,KAAK,WAAW;GAClB,MAAM,SAAS,KAAK,sBAAsB,UAAU,SAAS,WAAW;GACxE,IAAIC;AACJ,cAAW,MAAM,SAAS,OACxB,KAAI,gBAAgB,QAClB,cAAc;QAEd,cAAc,YAAY,OAAO,MAAM;AAG3C,OAAI,gBAAgB,OAClB,OAAM,IAAI,MACR;AAGJ,UAAO;IACL,aAAa,CAAC,WAAY;IAC1B,WAAW,YAAY;GACxB;EACF;AACD,SAAO,KAAK,sBAAsB,UAAU,SAAS,WAAW;CACjE;CAED,MAAM,sBACJR,UACAM,SACAG,aACqB;EACrB,MAAM,UAAU;EAChB,MAAM,eACJ,KAAK,gBAAgB,GAAG,QAAQ,CAAC,EAAE,KAAK,OAAO,cAAc,CAAC;EAChE,MAAM,WAAW,KAAK;EACtB,MAAM,WAAW,MAAM,KAAK,aAAa,UAAU,SAAS;GAC1D,eAAe;GACf;GACA;EACD,EAAC;EACF,MAAM,OAAO,MAAM,SAAS,MAAM;AAClC,MAAI,CAAC,SAAS,GACZ,OAAM,IAAI,MACR,CAAC,MAAM,EAAE,SAAS,OAAO,EAAE,EAAE,KAAK,WAAW,KAAK,UAAU,KAAK,EAAE;AAGvE,MAAI,KAAK,iBAAiB;GACxB,MAAM,mBACJ,6BAA6B,sBAAsB,UAAU,KAAK;AACpE,OAAI,qBAAqB,OACvB,OAAM,IAAI,MAAM;AAElB,UAAO;IACL,aAAa,CAAC,gBAAiB;IAC/B,WAAW,iBAAiB;GAC7B;EACF,OAAM;GACL,MAAM,OAAO,6BAA6B,cAAc,UAAU,KAAK;AACvE,UAAO,EAAE,aAAa,CAAC;IAAE;IAAM,SAAS,IAAI,UAAU;GAAO,CAAC,EAAE;EACjE;CACF;CAED,MAAM,aACJT,UACAK,SACAK,QAKA;EACA,MAAM,EAAE,eAAe,cAAc,UAAU,GAAG;EAClD,MAAM,EACJ,YACA,aACA,MACA,aACA,iBACA,OACD,GAAG,KAAK,iBAAiB,QAAQ;EAClC,MAAM,YAAY,KAAK,kBACnB,6BAA6B,qBAC3B,UACA,UACA,YACA,aACA,MACA,aACA,iBACA,MACD,GACD,6BAA6B,aAC3B,UACA,iCAAiC,SAAS,EAC1C,YACA,aACA,MACA,aACA,OAAO,eACP,gBACD;EAEL,MAAM,MAAM,IAAI,IACd,CAAC,QAAQ,EAAE,aAAa,OAAO,EAAE,KAAK,MAAM,CAAC,EAAE,eAAe;EAGhE,MAAM,UAAU,IAAI,YAAY;GAC9B,UAAU,IAAI;GACd,MAAM,IAAI;GACV,UAAU,IAAI;GACd,QAAQ;GACR,MAAM,KAAK,UAAU,UAAU;GAC/B,OAAO,OAAO,YAAY,IAAI,aAAa,SAAS,CAAC;GACrD,SAAS;IAEP,MAAM,IAAI;IACV,QAAQ;IACR,gBAAgB;IAChB,GAAI,KAAK,SACP,KAAK,uBACL,KAAK,oBAAoB;KACvB,wBAAwB,KAAK;KAC7B,sCAAsC,KAAK;KAC3C,mCAAmC,KAAK;IACzC;GACJ;EACF;EAED,MAAM,SAAS,IAAI,YAAY;GAC7B,aAAa,KAAK;GAClB,SAAS;GACT,QAAQ,KAAK;GACb,QAAQ;EACT;EAED,MAAM,gBAAgB,MAAM,OAAO,KAAK,QAAQ;EAGhD,MAAM,WAAW,MAAM,KAAK,OAAO,gBACjC,EAAE,QAAQ,QAAQ,OAAQ,GAC1B,YACE,KAAK,QAAQ,KAAK;GAChB,SAAS,cAAc;GACvB,MAAM,cAAc;GACpB,QAAQ,cAAc;EACvB,EAAC,CACL;AACD,SAAO;CACR;CAED,OAAO,sBACLV,UACAK,SACAE,YACqC;EACrC,MAAM,WAAW,KAAK;EACtB,MAAM,UAAU;EAEhB,MAAM,eACJ,KAAK,gBAAgB,GAAG,QAAQ,CAAC,EAAE,KAAK,OAAO,cAAc,CAAC;EAEhE,MAAM,gBACJ,aAAa,eACb,aAAa,YACb,aAAa,UACb,aAAa,YACT,gCACA;EAEN,MAAM,WAAW,MAAM,KAAK,aAAa,UAAU,SAAS;GAC1D;GACA;GACA;EACD,EAAC;AAEF,MAAI,SAAS,SAAS,OAAO,SAAS,UAAU,IAC9C,OAAM,MACJ,CAAC,iCAAiC,EAAE,aAAa,OAAO,EACtD,SAAS,OACV,CAAC,EAAE,SAAS,WAAW,EAAE,EAAE,MAAM,SAAS,MAAM,EAAE,CACpD;AAGH,MACE,aAAa,eACb,aAAa,YACb,aAAa,UACb,aAAa,WACb;GACA,MAAM,gBAAgB,eAAe,QAAQ;GAC7C,MAAM,SAAS,SAAS,MAAM,WAAW;GACzC,MAAM,UAAU,IAAI;AACpB,cAAW,MAAM,SAAS,KAAK,YAAY,OAAO,EAAE;IAClD,MAAM,QAAQ,KAAK,MAAM,OAAO,MAAM;AACtC,QACG,MAAM,QAAQ,mBAAmB,UAChC,MAAM,QAAQ,eAAe,UAAU,WACzC,MAAM,QAAQ,iBAAiB,UAAU,mBAEzC,OAAM,MAAM,CAAC,+BAA+B,EAAE,OAAO,CAAC;IAExD,MAAM,OAAO,KAAK,MAAM,QAAQ,OAAO,MAAM,KAAK,CAAC;AACnD,QAAI,KAAK,QACP,OAAM,IAAI,MAAM,KAAK;AAEvB,QAAI,KAAK,UAAU,QAAW;KAC5B,MAAM,cAAc,KAAK,MACvB,QAAQ,OACN,WAAW,KAAK,KAAK,KAAK,MAAM,EAAE,CAAC,MAAM,EAAE,YAAY,EAAE,IAAI,EAAE,CAChE,CACF;AACD,SAAI,KAAK,iBAAiB;MACxB,MAAMI,UAAQ,6BAA6B,sBACzC,UACA,aACA,EAIE,uBAAuB,CAAC,cACzB,EACF;AACD,UAAIA,YAAU,OACZ;AAEF,UACE,aAAa,eACbA,QAAM,gBAAgB,UAAU,QAGhC,OAAOA,QAAM,eAAe;MAE9B,MAAM,eACJA,QAAM,iBAAiB;AACzB,UACE,gBAAgB,QAChB,OAAO,iBAAiB,YACxB,YAAYA,QAAM,QAAQ,EAE1BA,QAAM,QAAQ,iBAAiB;OAC7B,cAAc,aAAa;OAC3B,eAAe,aAAa;OAC5B,cACE,aAAa,kBAAkB,aAAa;MAC/C;AAEH,UAAI,sBAAsBA,QAAM,EAAE;OAChC,MAAMA;OAED,YAAY,kBACfA,QAAM,MACN,QACA,QACA,QACA,QACA,EACE,eACD,EACF;MACF,OAEM,YAAY,kBAAkBA,QAAM,KAAK;KAEjD,OAAM;MACL,MAAM,OAAO,6BAA6B,cACxC,UACA,YACD;MACD,MAAMA,UAAQ,IAAI,oBAAoB;OACpC;OACA,SAAS,IAAI,eAAe,EAAE,SAAS,KAAM;MAC9C;MACD,MAAMA;MAED,YAAY,kBACf,MACA,QACA,QACA,QACA,QACA,EAAE,eAAO,EACV;KACF;IACF;GACF;EACF,OAAM;GACL,MAAM,OAAO,MAAM,SAAS,MAAM;GAClC,MAAM,OAAO,6BAA6B,cAAc,UAAU,KAAK;GACvE,MAAM,IAAI,oBAAoB;IAC5B;IACA,SAAS,IAAI,eAAe,EAAE,SAAS,KAAM;GAC9C;GAEI,YAAY,kBAAkB,KAAK;EACzC;CACF;CAGD,YAAYC,QAAa;EACvB,SAAS,cAAcC,GAAeC,GAAe;GACnD,MAAM,YAAY,IAAI,WAAW,EAAE,SAAS,EAAE;GAC9C,UAAU,IAAI,EAAE;GAChB,UAAU,IAAI,GAAG,EAAE,OAAO;AAC1B,UAAO;EACR;EAED,SAAS,iBAAiBC,QAAoB;AAC5C,OAAI,OAAO,aAAa,2BAA4B,QAAO;GAC3D,MAAM,OAAO,IAAI,SACf,OAAO,QACP,OAAO,YACP,OAAO;AAGT,UAAO,KAAK,UAAU,GAAG,MAAM;EAChC;AAED,SAAO,EACL,QAAQ,OAAO,iBAAiB;GAC9B,IAAI,aAAa,MAAM,OAAO,MAAM;GAEpC,IAAIA,SAAqB,IAAI,WAAW;AACxC,UAAO,CAAC,WAAW,MAAM;IACvB,MAAMC,QAAoB,WAAW;IAErC,SAAS,cAAc,QAAQ,MAAM;IACrC,IAAI,gBAAgB,iBAAiB,OAAO;AAE5C,WACE,OAAO,cAAc,8BACrB,OAAO,cAAc,eACrB;KACA,MAAM,OAAO,MAAM,GAAG,cAAc;KACpC,SAAS,OAAO,MAAM,cAAc;KACpC,gBAAgB,iBAAiB,OAAO;IACzC;IAED,aAAa,MAAM,OAAO,MAAM;GACjC;EACF,EACF;CACF;CAED,oBAAoB;AAClB,SAAO,CAAE;CACV;CAED,AAAS,UACPC,OACAC,SAKA;EACA,MAAM,WAAW,KAAK;AACtB,MAAI,aAAa,YACf,OAAM,IAAI,MACR;AAGJ,SAAO,KAAK,WAAW,EACrB,OAAO,YAAY,MAAM,CAC1B,EAAC;CACH;AACF;AAED,SAAS,sBACPC,GAC0B;AAC1B,QACE,MAAM,UAAa,OAAQ,EAA0B,WAAW;AAEnE;AAED,SAAS,kBAAkBC,OAAwB;CACjD,MAAM,oBAAoB,iBAAiB,MAAM;AAEjD,KACE,sBAAsB,eACtB,CAAC,MAAM,SAAS,YAAY,IAC5B,CAAC,MAAM,SAAS,oBAAoB,CAEpC,QAAO;AAGT,KAAI,sBAAsB,UAAU;AAClC,MAAI,MAAM,SAAS,eAAe,CAChC,QAAO;AAET,MAAI,MAAM,SAAS,oBAAoB,CACrC,QAAO;CAEV;AAED,QAAO;AACR;AAED,SAAS,iBAAiBC,SAA0B;CAClD,MAAM,QAAQ,QAAQ,MAAM,IAAI;AAChC,QAAO,YAAY,KAAK,CAAC,WAAW,MAAM,OAAO,OAAO;AACzD;AAED,SAAS,iBAAiBA,SAAyB;CACjD,MAAM,QAAQ,QAAQ,MAAM,IAAI;AAChC,KAAI,iBAAiB,QAAQ,CAC3B,QAAO,MAAM;KAEb,QAAO,MAAM;AAEhB"}