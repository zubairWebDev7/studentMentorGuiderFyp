{"version":3,"file":"buffer_token_memory.d.cts","names":["BaseLanguageModelInterface","InputValues","MemoryVariables","OutputValues","BaseChatMemory","BaseChatMemoryInput","ConversationTokenBufferMemoryInput","ConversationTokenBufferMemory","Promise"],"sources":["../../src/memory/buffer_token_memory.d.ts"],"sourcesContent":["import type { BaseLanguageModelInterface } from \"@langchain/core/language_models/base\";\nimport { InputValues, MemoryVariables, OutputValues } from \"@langchain/core/memory\";\nimport { BaseChatMemory, BaseChatMemoryInput } from \"./chat_memory.js\";\n/**\n * Interface for the input parameters of the `BufferTokenMemory` class.\n */\nexport interface ConversationTokenBufferMemoryInput extends BaseChatMemoryInput {\n    humanPrefix?: string;\n    aiPrefix?: string;\n    llm: BaseLanguageModelInterface;\n    memoryKey?: string;\n    maxTokenLimit?: number;\n}\n/**\n * Class that represents a conversation chat memory with a token buffer.\n * It extends the `BaseChatMemory` class and implements the\n * `ConversationTokenBufferMemoryInput` interface.\n * @example\n * ```typescript\n * const memory = new ConversationTokenBufferMemory({\n *   llm: new ChatOpenAI({ model: \"gpt-4o-mini\" }),\n *   maxTokenLimit: 10,\n * });\n *\n * // Save conversation context\n * await memory.saveContext({ input: \"hi\" }, { output: \"whats up\" });\n * await memory.saveContext({ input: \"not much you\" }, { output: \"not much\" });\n *\n * // Load memory variables\n * const result = await memory.loadMemoryVariables({});\n * console.log(result);\n * ```\n */\nexport declare class ConversationTokenBufferMemory extends BaseChatMemory implements ConversationTokenBufferMemoryInput {\n    humanPrefix: string;\n    aiPrefix: string;\n    memoryKey: string;\n    maxTokenLimit: number;\n    llm: BaseLanguageModelInterface;\n    constructor(fields: ConversationTokenBufferMemoryInput);\n    get memoryKeys(): string[];\n    /**\n     * Loads the memory variables. It takes an `InputValues` object as a\n     * parameter and returns a `Promise` that resolves with a\n     * `MemoryVariables` object.\n     * @param _values `InputValues` object.\n     * @returns A `Promise` that resolves with a `MemoryVariables` object.\n     */\n    loadMemoryVariables(_values: InputValues): Promise<MemoryVariables>;\n    /**\n     * Saves the context from this conversation to buffer. If the amount\n     * of tokens required to save the buffer exceeds MAX_TOKEN_LIMIT,\n     * prune it.\n     */\n    saveContext(inputValues: InputValues, outputValues: OutputValues): Promise<void>;\n}\n//# sourceMappingURL=buffer_token_memory.d.ts.map"],"mappings":";;;;;;;;AAMA;AA2BqBO,UA3BJD,kCAAAA,SAA2CD,mBA2BV,CAAA;EAKzCL,WAAAA,CAAAA,EAAAA,MAAAA;EACeM,QAAAA,CAAAA,EAAAA,MAAAA;EASSL,GAAAA,EAvCxBD,0BAuCwBC;EAAsBC,SAAAA,CAAAA,EAAAA,MAAAA;EAARM,aAAAA,CAAAA,EAAAA,MAAAA;;;;;;AAfwE;;;;;;;;;;;;;;;;cAAlGD,6BAAAA,SAAsCH,cAAAA,YAA0BE;;;;;OAK5EN;sBACeM;;;;;;;;;+BASSL,cAAcO,QAAQN;;;;;;2BAM1BD,2BAA2BE,eAAeK"}