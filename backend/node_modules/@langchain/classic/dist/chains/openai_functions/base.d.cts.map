{"version":3,"file":"base.d.cts","names":["BaseOutputParser","BasePromptTemplate","Runnable","RunnableInterface","BaseFunctionCallOptions","BaseLanguageModelInput","FunctionDefinition","InputValues","InteropZodObject","BaseMessage","JsonSchema7Type","CreateOpenAIFnRunnableConfig","RunInput","RunOutput","Record","Extract","createOpenAIFnRunnable","CreateStructuredOutputRunnableConfig","createStructuredOutputRunnable"],"sources":["../../../src/chains/openai_functions/base.d.ts"],"sourcesContent":["import type { BaseOutputParser } from \"@langchain/core/output_parsers\";\nimport type { BasePromptTemplate } from \"@langchain/core/prompts\";\nimport type { Runnable, RunnableInterface } from \"@langchain/core/runnables\";\nimport type { BaseFunctionCallOptions, BaseLanguageModelInput, FunctionDefinition } from \"@langchain/core/language_models/base\";\nimport { type InputValues, InteropZodObject } from \"@langchain/core/utils/types\";\nimport type { BaseMessage } from \"@langchain/core/messages\";\nimport { type JsonSchema7Type } from \"@langchain/core/utils/json_schema\";\n/**\n * Configuration params for the createOpenAIFnRunnable method.\n */\nexport type CreateOpenAIFnRunnableConfig<RunInput extends Record<string, any>, RunOutput> = {\n    functions: FunctionDefinition[];\n    /** Language model to use, assumed to support the OpenAI function-calling API. */\n    llm: RunnableInterface<BaseLanguageModelInput, BaseMessage, BaseFunctionCallOptions>;\n    /** BasePromptTemplate to pass to the model. */\n    prompt: BasePromptTemplate<InputValues<Extract<keyof RunInput, string>>>;\n    /**\n     * Only used if a single function is passed in. If `true`, then the model will be\n     * forced to use the given function. If `false`, then the model will be given the\n     * option to use the given function or not.\n     */\n    enforceSingleFunctionUsage?: boolean;\n    /**\n     * BaseLLMOutputParser to use for parsing model outputs.\n     * By default will be inferred from the function types.\n     */\n    outputParser?: BaseOutputParser<RunOutput>;\n};\n/**\n * Creates a runnable sequence that calls OpenAI functions.\n * @param config - The parameters required to create the runnable.\n * @returns A runnable sequence that will pass the given functions to the model when run.\n *\n * @example\n * ```typescript\n * const openAIFunction = {\n *   name: \"get_person_details\",\n *   description: \"Get details about a person\",\n *   parameters: {\n *     title: \"Person\",\n *     description: \"Identifying information about a person.\",\n *     type: \"object\",\n *     properties: {\n *       name: { title: \"Name\", description: \"The person's name\", type: \"string\" },\n *       age: { title: \"Age\", description: \"The person's age\", type: \"integer\" },\n *       fav_food: {\n *         title: \"Fav Food\",\n *         description: \"The person's favorite food\",\n *         type: \"string\",\n *       },\n *     },\n *     required: [\"name\", \"age\"],\n *   },\n * };\n *\n * const model = new ChatOpenAI();\n * const prompt = ChatPromptTemplate.fromMessages([\n *   [\"human\", \"Human description: {description}\"],\n * ]);\n * const outputParser = new JsonOutputFunctionsParser();\n *\n * const runnable = createOpenAIFnRunnable({\n *   functions: [openAIFunction],\n *   llm: model,\n *   prompt,\n *   enforceSingleFunctionUsage: true, // Default is true\n *   outputParser\n * });\n * const response = await runnable.invoke({\n *   description:\n *     \"My name's John Doe and I'm 30 years old. My favorite kind of food are chocolate chip cookies.\",\n * });\n *\n * console.log(response);\n *\n * // { name: 'John Doe', age: 30, fav_food: 'chocolate chip cookies' }\n * ```\n */\nexport declare function createOpenAIFnRunnable<RunInput extends Record<string, any> = Record<string, any>, RunOutput extends Record<string, any> = Record<string, any>>(config: CreateOpenAIFnRunnableConfig<RunInput, RunOutput>): Runnable<RunInput, RunOutput>;\n/**\n * Configuration params for the createStructuredOutputRunnable method.\n */\nexport type CreateStructuredOutputRunnableConfig<RunInput extends Record<string, any>, RunOutput> = {\n    /**\n     * Schema to output. Must be either valid JSONSchema or a Zod schema.\n     */\n    outputSchema: InteropZodObject | JsonSchema7Type;\n    /**\n     * Language model to use, assumed to support the OpenAI function-calling API.\n     */\n    llm: RunnableInterface<BaseLanguageModelInput, BaseMessage, BaseFunctionCallOptions>;\n    /** BasePromptTemplate to pass to the model. */\n    prompt: BasePromptTemplate<InputValues<Extract<keyof RunInput, string>>>;\n    /**\n     * BaseLLMOutputParser to use for parsing model outputs.\n     */\n    outputParser?: BaseOutputParser<RunOutput>;\n};\n/**\n * @deprecated Prefer the `.withStructuredOutput` method on chat model classes.\n *\n * Create a runnable that uses an OpenAI function to get a structured output.\n * @param config Params required to create the runnable.\n * @returns A runnable sequence that will pass the given function to the model when run.\n *\n * @example\n * ```typescript\n * import { createStructuredOutputRunnable } from \"@langchain/classic/chains/openai_functions\";\n * import { ChatOpenAI } from \"@langchain/openai\";\n * import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n * import { JsonOutputFunctionsParser } from \"@langchain/classic/output_parsers\";\n *\n * const jsonSchema = {\n *   title: \"Person\",\n *   description: \"Identifying information about a person.\",\n *   type: \"object\",\n *   properties: {\n *     name: { title: \"Name\", description: \"The person's name\", type: \"string\" },\n *     age: { title: \"Age\", description: \"The person's age\", type: \"integer\" },\n *     fav_food: {\n *       title: \"Fav Food\",\n *       description: \"The person's favorite food\",\n *       type: \"string\",\n *     },\n *   },\n *   required: [\"name\", \"age\"],\n * };\n *\n * const model = new ChatOpenAI({ model: \"gpt-4o-mini\" });\n * const prompt = ChatPromptTemplate.fromMessages([\n *   [\"human\", \"Human description: {description}\"],\n * ]);\n *\n * const outputParser = new JsonOutputFunctionsParser();\n *\n * // Also works with Zod schema\n * const runnable = createStructuredOutputRunnable({\n *   outputSchema: jsonSchema,\n *   llm: model,\n *   prompt,\n *   outputParser\n * });\n *\n * const response = await runnable.invoke({\n *   description:\n *     \"My name's John Doe and I'm 30 years old. My favorite kind of food are chocolate chip cookies.\",\n * });\n *\n * console.log(response);\n *\n * // { name: 'John Doe', age: 30, fav_food: 'chocolate chip cookies' }\n * ```\n */\nexport declare function createStructuredOutputRunnable<RunInput extends Record<string, any> = Record<string, any>, RunOutput extends Record<string, any> = Record<string, any>>(config: CreateStructuredOutputRunnableConfig<RunInput, RunOutput>): Runnable<RunInput, RunOutput>;\n//# sourceMappingURL=base.d.ts.map"],"mappings":";;;;;;;;;;;;AAUA;AAA0Dc,KAA9CH,4BAA8CG,CAAAA,iBAAAA,MAAAA,CAAAA,MAAAA,EAAAA,GAAAA,CAAAA,EAAAA,SAAAA,CAAAA,GAAAA;EAC3CR,SAAAA,EAAAA,kBAAAA,EAAAA;EAEYD;EAAwBI,GAAAA,EAA1CN,iBAA0CM,CAAxBJ,sBAAwBI,EAAAA,WAAAA,EAAaL,uBAAbK,CAAAA;EAAaL;EAAvDD,MAAAA,EAEGF,kBAFHE,CAEsBI,WAFtBJ,CAEkCY,OAFlCZ,CAAAA,MAEgDS,QAFhDT,EAAAA,MAAAA,CAAAA,CAAAA,CAAAA;EAEgDS;;;;;EAWtCZ,0BAAAA,CAAAA,EAAAA,OAAAA;EAAgB;AAoDnC;;;EAA6Hc,YAAAA,CAAAA,EApD1Gd,gBAoD0Gc,CApDzFD,SAoDyFC,CAAAA;CAAsBA;;;;;;;AAAyF;AAI5O;;;;;;;;;;;;;;AAcmC;AAyDnC;;;;;;;;;;;AAA4P;;;;;;;;;;;;;;;;;iBA3EpOE,wCAAwCF,sBAAsBA,uCAAuCA,sBAAsBA,6BAA6BH,6BAA6BC,UAAUC,aAAaX,SAASU,UAAUC;;;;KAI3OI,sDAAsDH;;;;gBAIhDN,mBAAmBE;;;;OAI5BP,kBAAkBE,wBAAwBI,aAAaL;;UAEpDH,mBAAmBM,YAAYQ,cAAcH;;;;iBAItCZ,iBAAiBa;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;iBAyDZK,gDAAgDJ,sBAAsBA,uCAAuCA,sBAAsBA,6BAA6BG,qCAAqCL,UAAUC,aAAaX,SAASU,UAAUC"}