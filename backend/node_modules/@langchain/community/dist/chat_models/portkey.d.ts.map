{"version":3,"file":"portkey.d.ts","names":["LLMOptions","CallbackManagerForLLMRun","BaseMessage","ChatResult","ChatGenerationChunk","BaseChatModel","PortkeySession","PortkeyChat","Partial","Promise","AsyncGenerator"],"sources":["../../src/chat_models/portkey.d.ts"],"sourcesContent":["import { LLMOptions } from \"portkey-ai\";\nimport { CallbackManagerForLLMRun } from \"@langchain/core/callbacks/manager\";\nimport { BaseMessage } from \"@langchain/core/messages\";\nimport { ChatResult, ChatGenerationChunk } from \"@langchain/core/outputs\";\nimport { BaseChatModel } from \"@langchain/core/language_models/chat_models\";\nimport { PortkeySession } from \"../llms/portkey.js\";\nexport declare class PortkeyChat extends BaseChatModel {\n    apiKey?: string;\n    baseURL?: string;\n    mode?: string;\n    llms?: [LLMOptions] | null;\n    session: PortkeySession;\n    constructor(init?: Partial<PortkeyChat>);\n    _llmType(): string;\n    _generate(messages: BaseMessage[], options: this[\"ParsedCallOptions\"], _?: CallbackManagerForLLMRun): Promise<ChatResult>;\n    _streamResponseChunks(messages: BaseMessage[], options: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): AsyncGenerator<ChatGenerationChunk>;\n    _combineLLMOutput(): {};\n}\n//# sourceMappingURL=portkey.d.ts.map"],"mappings":";;;;;;;;cAMqBO,WAAAA,SAAoBF,aAAAA;;EAApBE,OAAAA,CAAAA,EAAAA,MAAW;EAIpBP,IAAAA,CAAAA,EAAAA,MAAAA;EACCM,IAAAA,CAAAA,EAAAA,CADDN,UACCM,CAAAA,GAAAA,IAAAA;EACkBC,OAAAA,EADlBD,cACkBC;EAARC,WAAAA,CAAAA,IAAAA,CAAAA,EAAAA,OAAAA,CAAQD,WAARC,CAAAA;EAECN,QAAAA,CAAAA,CAAAA,EAAAA,MAAAA;EAAuDD,SAAAA,CAAAA,QAAAA,EAAvDC,WAAuDD,EAAAA,EAAAA,OAAAA,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,EAAAA,CAAAA,CAAAA,EAAAA,wBAAAA,CAAAA,EAA2BQ,OAA3BR,CAAmCE,UAAnCF,CAAAA;EAAmCE,qBAAAA,CAAAA,QAAAA,EAC9ED,WAD8EC,EAAAA,EAAAA,OAAAA,EAAAA,IAAAA,CAAAA,mBAAAA,CAAAA,EAAAA,UAAAA,CAAAA,EACdF,wBADcE,CAAAA,EACaO,cADbP,CAC4BC,mBAD5BD,CAAAA;EAARM,iBAAAA,CAAAA,CAAAA,EAAAA,CAAAA,CAAAA"}