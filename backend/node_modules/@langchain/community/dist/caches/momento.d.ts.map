{"version":3,"file":"momento.d.ts","names":["ICacheClient","BaseCache","Generation","MomentoCacheProps","MomentoCache","Promise"],"sources":["../../src/caches/momento.d.ts"],"sourcesContent":["import { ICacheClient } from \"@gomomento/sdk-core\";\nimport { BaseCache } from \"@langchain/core/caches\";\nimport { Generation } from \"@langchain/core/outputs\";\n/**\n * The settings to instantiate the Momento standard cache.\n */\nexport interface MomentoCacheProps {\n    /**\n     * The Momento cache client.\n     */\n    client: ICacheClient;\n    /**\n     * The name of the cache to use to store the data.\n     */\n    cacheName: string;\n    /**\n     * The time to live for the cache items. If not specified,\n     * the cache client default is used.\n     */\n    ttlSeconds?: number;\n    /**\n     * If true, ensure that the cache exists before returning.\n     * If false, the cache is not checked for existence.\n     * Defaults to true.\n     */\n    ensureCacheExists?: true;\n}\n/**\n * A cache that uses Momento as the backing store.\n * See https://gomomento.com.\n * @example\n * ```typescript\n * const cache = new MomentoCache({\n *   client: new CacheClient({\n *     configuration: Configurations.Laptop.v1(),\n *     credentialProvider: CredentialProvider.fromEnvironmentVariable({\n *       environmentVariableName: \"MOMENTO_API_KEY\",\n *     }),\n *     defaultTtlSeconds: 60 * 60 * 24, // Cache TTL set to 24 hours.\n *   }),\n *   cacheName: \"langchain\",\n * });\n * // Initialize the OpenAI model with Momento cache for caching responses\n * const model = new ChatOpenAI({\n *   model: \"gpt-4o-mini\",\n *   cache,\n * });\n * await model.invoke(\"How are you today?\");\n * const cachedValues = await cache.lookup(\"How are you today?\", \"llmKey\");\n * ```\n */\nexport declare class MomentoCache extends BaseCache {\n    private client;\n    private readonly cacheName;\n    private readonly ttlSeconds?;\n    private constructor();\n    /**\n     * Create a new standard cache backed by Momento.\n     *\n     * @param {MomentoCacheProps} props The settings to instantiate the cache.\n     * @param {ICacheClient} props.client The Momento cache client.\n     * @param {string} props.cacheName The name of the cache to use to store the data.\n     * @param {number} props.ttlSeconds The time to live for the cache items. If not specified,\n     * the cache client default is used.\n     * @param {boolean} props.ensureCacheExists If true, ensure that the cache exists before returning.\n     * If false, the cache is not checked for existence. Defaults to true.\n     * @throws {@link InvalidArgumentError} if {@link props.ttlSeconds} is not strictly positive.\n     * @returns The Momento-backed cache.\n     */\n    static fromProps(props: MomentoCacheProps): Promise<MomentoCache>;\n    /**\n     * Validate the user-specified TTL, if provided, is strictly positive.\n     * @param ttlSeconds The TTL to validate.\n     */\n    private validateTtlSeconds;\n    /**\n     * Lookup LLM generations in cache by prompt and associated LLM key.\n     * @param prompt The prompt to lookup.\n     * @param llmKey The LLM key to lookup.\n     * @returns The generations associated with the prompt and LLM key, or null if not found.\n     */\n    lookup(prompt: string, llmKey: string): Promise<Generation[] | null>;\n    /**\n     * Update the cache with the given generations.\n     *\n     * Note this overwrites any existing generations for the given prompt and LLM key.\n     *\n     * @param prompt The prompt to update.\n     * @param llmKey The LLM key to update.\n     * @param value The generations to store.\n     */\n    update(prompt: string, llmKey: string, value: Generation[]): Promise<void>;\n}\n//# sourceMappingURL=momento.d.ts.map"],"mappings":";;;;;;;;AAMA;AA6CqBI,UA7CJD,iBAAAA,CA6CgB;EAkBLA;;;EAYwBD,MAAAA,EAvExCF,YAuEwCE;EAARG;;;EA9BFJ,SAAAA,EAAAA,MAAAA;EAAS;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;cAA9BG,YAAAA,SAAqBH,SAAAA;;;;;;;;;;;;;;;;;;0BAkBdE,oBAAoBE,QAAQD;;;;;;;;;;;;0CAYZC,QAAQH;;;;;;;;;;gDAUFA,eAAeG"}