{"version":3,"file":"openai_whisper_audio.d.ts","names":["ClientOptions","OpenAIClient","Document","BufferLoader","OpenAIWhisperAudio","Blob","Audio","TranscriptionCreateParams","Partial","Buffer","Record","Promise"],"sources":["../../../src/document_loaders/fs/openai_whisper_audio.d.ts"],"sourcesContent":["import { type ClientOptions, OpenAIClient } from \"@langchain/openai\";\nimport { Document } from \"@langchain/core/documents\";\nimport { BufferLoader } from \"@langchain/classic/document_loaders/fs/buffer\";\n/**\n * @example\n * ```typescript\n * const loader = new OpenAIWhisperAudio(\n *   \"./src/document_loaders/example_data/test.mp3\",\n * );\n * const docs = await loader.load();\n * console.log(docs);\n * ```\n */\nexport declare class OpenAIWhisperAudio extends BufferLoader {\n    private readonly openAIClient;\n    private readonly transcriptionCreateParams?;\n    constructor(filePathOrBlob: string | Blob, fields?: {\n        clientOptions?: ClientOptions;\n        transcriptionCreateParams?: Partial<OpenAIClient.Audio.TranscriptionCreateParams>;\n    });\n    protected parse(raw: Buffer, metadata: Record<string, string>): Promise<Document[]>;\n}\n//# sourceMappingURL=openai_whisper_audio.d.ts.map"],"mappings":";;;;;;;;AAaA;;;;;;;;AAOoEW,cAP/CP,kBAAAA,SAA2BD,YAAAA,CAOoBQ;EAPpBR,iBAAAA,YAAAA;EAAY,iBAAA,yBAAA;uCAGnBE;oBACjBL;gCACYQ,QAAQP,YAAAA,CAAaK,KAAAA,CAAMC;;uBAEtCE,kBAAkBC,yBAAyBC,QAAQT"}