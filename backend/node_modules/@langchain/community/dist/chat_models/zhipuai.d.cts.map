{"version":3,"file":"zhipuai.d.cts","names":["BaseChatModel","BaseChatModelCallOptions","BindToolsInput","BaseChatModelParams","BaseMessage","AIMessageChunk","ChatGenerationChunk","ChatResult","CallbackManagerForLLMRun","Runnable","BaseLanguageModelInput","ToolDefinition","ZhipuMessageRole","ZhipuMessage","ModelName","NonNullable","ChatZhipuAICallOptions","ChatCompletionRequest","ChatZhipuAIParams","ChatZhipuAI","Partial","Omit","Promise","AbortSignal","MessageEvent","AsyncGenerator"],"sources":["../../src/chat_models/zhipuai.d.ts"],"sourcesContent":["import { BaseChatModel, BaseChatModelCallOptions, BindToolsInput, type BaseChatModelParams } from \"@langchain/core/language_models/chat_models\";\nimport { type BaseMessage, AIMessageChunk } from \"@langchain/core/messages\";\nimport { ChatGenerationChunk, type ChatResult } from \"@langchain/core/outputs\";\nimport { type CallbackManagerForLLMRun } from \"@langchain/core/callbacks/manager\";\nimport { Runnable } from \"@langchain/core/runnables\";\nimport { BaseLanguageModelInput, ToolDefinition } from \"@langchain/core/language_models/base\";\nexport type ZhipuMessageRole = \"system\" | \"assistant\" | \"user\";\ninterface ZhipuMessage {\n    role: ZhipuMessageRole;\n    content: string;\n}\n/**\n * Interface representing a request for a chat completion.\n *\n * See https://open.bigmodel.cn/dev/howuse/model\n */\ntype ModelName = (string & NonNullable<unknown>) | \"chatglm_pro\" | \"chatglm_std\" | \"chatglm_lite\" | \"glm-4\" | \"glm-4v\" | \"glm-3-turbo\" | \"chatglm_turbo\";\nexport interface ChatZhipuAICallOptions extends BaseChatModelCallOptions {\n    tools?: BindToolsInput[];\n}\ninterface ChatCompletionRequest {\n    model: ModelName;\n    messages?: ZhipuMessage[];\n    tools?: ToolDefinition[];\n    do_sample?: boolean;\n    stream?: boolean;\n    request_id?: string;\n    max_tokens?: number | null;\n    top_p?: number | null;\n    top_k?: number | null;\n    temperature?: number | null;\n    stop?: string[];\n}\n/**\n * Interface defining the input to the ZhipuAIChatInput class.\n */\nexport interface ChatZhipuAIParams {\n    /**\n     * @default \"glm-3-turbo\"\n     * Alias for `model`\n     */\n    modelName: ModelName;\n    /**\n     * @default \"glm-3-turbo\"\n     */\n    model: ModelName;\n    /** Whether to stream the results or not. Defaults to false. */\n    streaming?: boolean;\n    /** Messages to pass as a prefix to the prompt */\n    messages?: ZhipuMessage[];\n    /**\n     * API key to use when making requests. Defaults to the value of\n     * `ZHIPUAI_API_KEY` environment variable.\n     * Alias for `apiKey`\n     */\n    zhipuAIApiKey?: string;\n    /**\n     * API key to use when making requests. Defaults to the value of\n     * `ZHIPUAI_API_KEY` environment variable.\n     */\n    apiKey?: string;\n    /** Amount of randomness injected into the response. Ranges\n     * from 0 to 1 (0 is not included). Use temp closer to 0 for analytical /\n     * multiple choice, and temp closer to 1 for creative\n     * and generative tasks. Defaults to 0.95\n     */\n    temperature?: number;\n    /** Total probability mass of tokens to consider at each step. Range\n     * from 0 to 1 Defaults to 0.7\n     */\n    topP?: number;\n    /**\n     * Unique identifier for the request. Defaults to a random UUID.\n     */\n    requestId?: string;\n    /**\n     * turn on sampling strategy when do_sample is true,\n     * do_sample is false, temperature、top_p will not take effect\n     */\n    doSample?: boolean;\n    /**\n     * max value is 8192，defaults to 1024\n     */\n    maxTokens?: number;\n    stop?: string[];\n}\nexport declare class ChatZhipuAI extends BaseChatModel<ChatZhipuAICallOptions> implements ChatZhipuAIParams {\n    static lc_name(): string;\n    get callKeys(): string[];\n    get lc_secrets(): {\n        zhipuAIApiKey: string;\n        apiKey: string;\n    };\n    get lc_aliases(): undefined;\n    zhipuAIApiKey?: string;\n    apiKey?: string;\n    streaming: boolean;\n    doSample?: boolean;\n    messages?: ZhipuMessage[];\n    requestId?: string;\n    modelName: ChatCompletionRequest[\"model\"];\n    model: ChatCompletionRequest[\"model\"];\n    apiUrl: string;\n    maxTokens?: number | undefined;\n    temperature?: number | undefined;\n    topP?: number | undefined;\n    stop?: string[];\n    constructor(fields?: Partial<ChatZhipuAIParams> & BaseChatModelParams);\n    /**\n     * Get the parameters used to invoke the model\n     */\n    invocationParams(options?: this[\"ParsedCallOptions\"]): Omit<ChatCompletionRequest, \"messages\">;\n    /**\n     * Get the identifying parameters for the model\n     */\n    identifyingParams(): Omit<ChatCompletionRequest, \"messages\">;\n    /** @ignore */\n    _generate(messages: BaseMessage[], options?: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): Promise<ChatResult>;\n    bindTools(tools: BindToolsInput[], kwargs?: Partial<this[\"ParsedCallOptions\"]>): Runnable<BaseLanguageModelInput, AIMessageChunk, BaseChatModelCallOptions>;\n    /** @ignore */\n    completionWithRetry(request: ChatCompletionRequest, stream: boolean, signal?: AbortSignal, onmessage?: (event: MessageEvent) => void): Promise<any>;\n    private createZhipuStream;\n    private _deserialize;\n    _streamResponseChunks(messages: BaseMessage[], options?: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): AsyncGenerator<ChatGenerationChunk>;\n    _llmType(): string;\n    /** @ignore */\n    _combineLLMOutput(): never[];\n}\nexport {};\n//# sourceMappingURL=zhipuai.d.ts.map"],"mappings":";;;;;;;;KAMYY,gBAAAA;UACFC,YAAAA;EADED,IAAAA,EAEFA,gBAFkB;EAClBC,OAAAA,EAAAA,MAAY;AACI;AAS1B;AAEC;;;;AAIyB,KAPrBC,SAAAA,GAOqB,CAAA,MAAA,GAPCC,WAOD,CAAA,OAAA,CAAA,CAAA,GAAA,aAAA,GAAA,aAAA,GAAA,cAAA,GAAA,OAAA,GAAA,QAAA,GAAA,aAAA,GAAA,eAAA;AAaTG,UAnBAF,sBAAAA,SAA+Bf,wBAmBd,CAAA;EAKnBa,KAAAA,CAAAA,EAvBHZ,cAuBGY,EAAAA;;UArBLG,qBAAAA,CA6BKJ;EAAY,KAAA,EA5BhBC,SA4BgB;EAqCNK,QAAAA,CAAAA,EAhENN,YAgEiB,EAAA;EAAuBG,KAAAA,CAAAA,EA/D3CL,cA+D2CK,EAAAA;EAYxCH,SAAAA,CAAAA,EAAAA,OAAAA;EAEAI,MAAAA,CAAAA,EAAAA,OAAAA;EACJA,UAAAA,CAAAA,EAAAA,MAAAA;EAMsBC,UAAAA,CAAAA,EAAAA,MAAAA,GAAAA,IAAAA;EAARE,KAAAA,CAAAA,EAAAA,MAAAA,GAAAA,IAAAA;EAA6BjB,KAAAA,CAAAA,EAAAA,MAAAA,GAAAA,IAAAA;EAIUc,WAAAA,CAAAA,EAAAA,MAAAA,GAAAA,IAAAA;EAALI,IAAAA,CAAAA,EAAAA,MAAAA,EAAAA;;;;;AAMiEd,UAjF3GW,iBAAAA,CAiF2GX;EAARe;;;;EACEjB,SAAAA,EA7EvGS,SA6EuGT;EAAgBJ;;;EAEpDsB,KAAAA,EA3EvET,SA2EuES;EAAiCC;EAAwBF,SAAAA,CAAAA,EAAAA,OAAAA;EAGvGlB;EAAiEI,QAAAA,CAAAA,EA1EtFK,YA0EsFL,EAAAA;EAA0CF;;;;AArCpC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;cAAtFa,WAAAA,SAAoBnB,cAAcgB,mCAAmCE;;;;;;;;;;;;aAY3EL;;aAEAI;SACJA;;;;;;uBAMcG,QAAQF,qBAAqBf;;;;yDAIKkB,KAAKJ;;;;uBAIvCI,KAAKJ;;sBAENb,iEAAiEI,2BAA2Bc,QAAQf;mBACvGL,2BAA2BkB,qCAAqCX,SAASC,wBAAwBL,gBAAgBJ;;+BAErGgB,iDAAiDM,iCAAiCC,wBAAwBF;;;kCAGvGlB,iEAAiEI,2BAA2BiB,eAAenB"}