{"version":3,"file":"perplexity.d.cts","names":["BaseMessage","BaseChatModel","BaseChatModelParams","BaseChatModelCallOptions","CallbackManagerForLLMRun","ChatGenerationChunk","ChatResult","Runnable","BaseLanguageModelInput","StructuredOutputMethodOptions","InteropZodType","PerplexityRole","WebSearchOptions","PerplexityChatInput","PerplexityChatCallOptions","Record","ChatPerplexity","RunOutput","Promise","AsyncGenerator"],"sources":["../../src/chat_models/perplexity.d.ts"],"sourcesContent":["import { BaseMessage } from \"@langchain/core/messages\";\nimport { BaseChatModel, BaseChatModelParams, BaseChatModelCallOptions } from \"@langchain/core/language_models/chat_models\";\nimport { CallbackManagerForLLMRun } from \"@langchain/core/callbacks/manager\";\nimport { ChatGenerationChunk, ChatResult } from \"@langchain/core/outputs\";\nimport { Runnable } from \"@langchain/core/runnables\";\nimport { BaseLanguageModelInput, StructuredOutputMethodOptions } from \"@langchain/core/language_models/base\";\nimport { InteropZodType } from \"@langchain/core/utils/types\";\n/**\n * Type representing the role of a message in the Perplexity chat model.\n */\nexport type PerplexityRole = \"system\" | \"user\" | \"assistant\";\nexport interface WebSearchOptions {\n    /**\n     * Determines how much search context is retrieved for the model.\n     * Options are: low (minimizes context for cost savings but less comprehensive answers), medium (balanced approach suitable for most queries), and high (maximizes context for comprehensive answers but at higher cost).\n     */\n    search_context_size?: \"low\" | \"medium\" | \"high\";\n    /**\n     * To refine search results based on geography, you can specify an approximate user location.\n     */\n    user_location?: {\n        /**\n         * The latitude of the user's location.\n         */\n        latitude: number;\n        /**\n         * The longitude of the user's location.\n         */\n        longitude: number;\n        /**\n         * The two letter ISO country code of the user's location.\n         */\n        country: string;\n    };\n}\n/**\n * Interface defining the parameters for the Perplexity chat model.\n */\nexport interface PerplexityChatInput extends BaseChatModelParams {\n    /** Model name to use */\n    model: string;\n    /** Maximum number of tokens to generate */\n    maxTokens?: number;\n    /** Temperature parameter between 0 and 2 */\n    temperature?: number;\n    /** Top P parameter between 0 and 1 */\n    topP?: number;\n    /** Search domain filter - limit the citations used by the online model to URLs from the specified domains. */\n    searchDomainFilter?: unknown[];\n    /** Whether to return images */\n    returnImages?: boolean;\n    /** Determines whether or not a request to an online model should return related questions. */\n    returnRelatedQuestions?: boolean;\n    /** Returns search results within the specified time interval - does not apply to images. Values include month, week, day, hour. */\n    searchRecencyFilter?: string;\n    /** Top K parameter between 1 and 2048 */\n    topK?: number;\n    /** Presence penalty between -2 and 2 */\n    presencePenalty?: number;\n    /** Frequency penalty greater than 0 */\n    frequencyPenalty?: number;\n    /** API key for Perplexity.  Defaults to the value of\n     * PERPLEXITY_API_KEY environment variable.\n     */\n    apiKey?: string;\n    /** Whether to stream the results or not */\n    streaming?: boolean;\n    /** Timeout for requests to Perplexity */\n    timeout?: number;\n    /** Controls the search mode used for the request. When set to 'academic', results will prioritize scholarly sources. */\n    searchMode?: \"academic\" | \"web\";\n    /** Controls how much computational effort the AI dedicates to each query for deep research models. Only applicable for sonar-deep-research. */\n    reasoningEffort?: \"low\" | \"medium\" | \"high\";\n    /** Filters search results to only include content published after this date. */\n    searchAfterDateFilter?: string;\n    /** Filters search results to only include content published before this date. */\n    searchBeforeDateFilter?: string;\n    /** Filters search results to only include content last updated after this date. */\n    lastUpdatedAfterFilter?: string;\n    /** Filters search results to only include content last updated before this date. */\n    lastUpdatedBeforeFilter?: string;\n    /** When set to true, disables web search completely and the model will only use its training data to respond. This is useful when you want deterministic responses without external information. */\n    disableSearch?: boolean;\n    /** Enables a classifier that decides if web search is needed based on your query. */\n    enableSearchClassifier?: boolean;\n    /**\n     * Configuration for using web search in model responses.\n     */\n    webSearchOptions?: WebSearchOptions;\n}\nexport interface PerplexityChatCallOptions extends BaseChatModelCallOptions {\n    response_format?: {\n        type: \"json_schema\";\n        json_schema: {\n            name: string;\n            description: string;\n            schema: Record<string, unknown>;\n        };\n    };\n}\n/**\n * Wrapper around Perplexity large language models that use the Chat endpoint.\n */\nexport declare class ChatPerplexity extends BaseChatModel<PerplexityChatCallOptions> implements PerplexityChatInput {\n    static lc_name(): string;\n    model: string;\n    temperature?: number;\n    maxTokens?: number;\n    apiKey?: string;\n    timeout?: number;\n    streaming?: boolean;\n    topP?: number;\n    searchDomainFilter?: any[];\n    returnImages?: boolean;\n    returnRelatedQuestions?: boolean;\n    searchRecencyFilter?: string;\n    topK?: number;\n    presencePenalty?: number;\n    frequencyPenalty?: number;\n    searchMode?: \"academic\" | \"web\";\n    reasoningEffort?: \"low\" | \"medium\" | \"high\";\n    searchAfterDateFilter?: string;\n    searchBeforeDateFilter?: string;\n    lastUpdatedAfterFilter?: string;\n    lastUpdatedBeforeFilter?: string;\n    disableSearch?: boolean;\n    enableSearchClassifier?: boolean;\n    webSearchOptions?: WebSearchOptions;\n    private client;\n    constructor(fields: PerplexityChatInput);\n    _llmType(): string;\n    /**\n     * Get the parameters used to invoke the model\n     */\n    invocationParams(options?: this[\"ParsedCallOptions\"]): {\n        model: string;\n        temperature: number | undefined;\n        max_tokens: number | undefined;\n        stream: boolean | undefined;\n        top_p: number | undefined;\n        return_images: boolean | undefined;\n        return_related_questions: boolean | undefined;\n        top_k: number | undefined;\n        presence_penalty: number | undefined;\n        frequency_penalty: number | undefined;\n        response_format: {\n            type: \"json_schema\";\n            json_schema: {\n                name: string;\n                description: string;\n                schema: Record<string, unknown>;\n            };\n        } | undefined;\n        search_domain_filter: any[] | undefined;\n        search_recency_filter: string | undefined;\n        search_mode: \"academic\" | \"web\" | undefined;\n        reasoning_effort: \"high\" | \"low\" | \"medium\" | undefined;\n        search_after_date_filter: string | undefined;\n        search_before_date_filter: string | undefined;\n        last_updated_after_filter: string | undefined;\n        last_updated_before_filter: string | undefined;\n        disable_search: boolean | undefined;\n        enable_search_classifier: boolean | undefined;\n        web_search_options: Record<string, unknown>;\n    };\n    /**\n     * Convert a message to a format that the model expects\n     */\n    private messageToPerplexityRole;\n    _generate(messages: BaseMessage[], options: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): Promise<ChatResult>;\n    _streamResponseChunks(messages: BaseMessage[], options: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): AsyncGenerator<ChatGenerationChunk>;\n    withStructuredOutput<RunOutput extends Record<string, any> = Record<string, any>>(outputSchema: InteropZodType<RunOutput> | Record<string, any>, config?: StructuredOutputMethodOptions<false>): Runnable<BaseLanguageModelInput, RunOutput>;\n    withStructuredOutput<RunOutput extends Record<string, any> = Record<string, any>>(outputSchema: InteropZodType<RunOutput> | Record<string, any>, config?: StructuredOutputMethodOptions<true>): Runnable<BaseLanguageModelInput, {\n        raw: BaseMessage;\n        parsed: RunOutput;\n    }>;\n}\n//# sourceMappingURL=perplexity.d.ts.map"],"mappings":";;;;;;;;;;;;AAUA;AACiBY,KADLD,cAAAA,GACqB,QAAA,GAAA,MAAA,GAAA,WAAA;AA2BhBE,UA3BAD,gBAAAA,CA2BmB;EAoDnBE;AAajB;;;EA0BwBD,mBAAAA,CAAAA,EAAAA,KAAAA,GAAAA,QAAAA,GAAAA,MAAAA;EAqBAE;;;EAmBgEX,aAAAA,CAAAA,EAAAA;IAAmCE;;;IACvBF,QAAAA,EAAAA,MAAAA;IAA0CC;;;IAC7EU,SAAAA,EAAAA,MAAAA;IAAkDE;;;IAA2CR,OAAAA,EAAAA,MAAAA;EAAgDD,CAAAA;;;;;AAC3FS,UAtIlGJ,mBAAAA,SAA4BX,mBAsIsEe,CAAAA;EAAfP;EAA4BK,KAAAA,EAAAA,MAAAA;EAA8BN;EAA+CD,SAAAA,CAAAA,EAAAA,MAAAA;EAChMR;EACGiB,WAAAA,CAAAA,EAAAA,MAAAA;EAFoLV;EArExJN,IAAAA,CAAAA,EAAAA,MAAAA;EAAoDY;EAAmB,kBAAA,CAAA,EAAA,OAAA,EAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;qBAf5FD;;UAENE,yBAAAA,SAAkCX;;;;;;cAM/BY;;;;;;;cAOCC,cAAAA,SAAuBf,cAAca,sCAAsCD;;;;;;;;;;;;;;;;;;;;;;;;qBAwBzED;;sBAECC;;;;;;;;;;;;;;;;;;;;;gBAqBAE;;;;;;;;;;;;;wBAaIA;;;;;;sBAMJf,gEAAgEI,2BAA2Bc,QAAQZ;kCACvFN,gEAAgEI,2BAA2Be,eAAed;yCACnGU,sBAAsBA,mCAAmCL,eAAeO,aAAaF,8BAA8BN,uCAAuCF,SAASC,wBAAwBS;yCAC3LF,sBAAsBA,mCAAmCL,eAAeO,aAAaF,8BAA8BN,sCAAsCF,SAASC;SAChMR;YACGiB"}