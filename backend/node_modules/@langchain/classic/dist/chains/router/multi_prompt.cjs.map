{"version":3,"file":"multi_prompt.cjs","names":["MultiRouteChain","llm: BaseLanguageModelInterface","promptNames: string[]","promptDescriptions: string[]","promptTemplates: string[] | PromptTemplate[]","defaultChain?: BaseChain","options?: Omit<MultiRouteChainInput, \"defaultChain\">","zipEntries","z","RouterOutputParser","STRUCTURED_MULTI_PROMPT_ROUTER_TEMPLATE","PromptTemplate","LLMRouterChain","myPrompt: string | PromptTemplate","LLMChain","ConversationChain"],"sources":["../../../src/chains/router/multi_prompt.ts"],"sourcesContent":["import type { BaseLanguageModelInterface } from \"@langchain/core/language_models/base\";\nimport { z } from \"zod/v3\";\nimport { interpolateFString, PromptTemplate } from \"@langchain/core/prompts\";\nimport { MultiRouteChain, MultiRouteChainInput } from \"./multi_route.js\";\nimport { STRUCTURED_MULTI_PROMPT_ROUTER_TEMPLATE } from \"./multi_prompt_prompt.js\";\nimport { BaseChain } from \"../../chains/base.js\";\nimport { LLMChain, LLMChainInput } from \"../../chains/llm_chain.js\";\nimport { LLMRouterChain } from \"./llm_router.js\";\nimport { ConversationChain } from \"../../chains/conversation.js\";\nimport { zipEntries } from \"./utils.js\";\nimport { RouterOutputParser } from \"../../output_parsers/router.js\";\n\n/**\n * A class that represents a multi-prompt chain in the LangChain\n * framework. It extends the MultiRouteChain class and provides additional\n * functionality specific to multi-prompt chains.\n * @example\n * ```typescript\n * const multiPromptChain = MultiPromptChain.fromLLMAndPrompts(\n *   new ChatOpenAI({ model: \"gpt-4o-mini\" }),\n *   {\n *     promptNames: [\"physics\", \"math\", \"history\"],\n *     promptDescriptions: [\n *       \"Good for answering questions about physics\",\n *       \"Good for answering math questions\",\n *       \"Good for answering questions about history\",\n *     ],\n *     promptTemplates: [\n *       `You are a very smart physics professor. Here is a question:\\n{input}\\n`,\n *       `You are a very good mathematician. Here is a question:\\n{input}\\n`,\n *       `You are a very smart history professor. Here is a question:\\n{input}\\n`,\n *     ],\n *   }\n * );\n * const result = await multiPromptChain.call({\n *   input: \"What is the speed of light?\",\n * });\n * ```\n */\nexport class MultiPromptChain extends MultiRouteChain {\n  /**\n   * @deprecated Use `fromLLMAndPrompts` instead\n   */\n  static fromPrompts(\n    llm: BaseLanguageModelInterface,\n    promptNames: string[],\n    promptDescriptions: string[],\n    promptTemplates: string[] | PromptTemplate[],\n    defaultChain?: BaseChain,\n    options?: Omit<MultiRouteChainInput, \"defaultChain\">\n  ) {\n    return MultiPromptChain.fromLLMAndPrompts(llm, {\n      promptNames,\n      promptDescriptions,\n      promptTemplates,\n      defaultChain,\n      multiRouteChainOpts: options,\n    });\n  }\n\n  /**\n   * A static method that creates an instance of MultiPromptChain from a\n   * BaseLanguageModel and a set of prompts. It takes in optional parameters\n   * for the default chain and additional options.\n   * @param llm A BaseLanguageModel instance.\n   * @param promptNames An array of prompt names.\n   * @param promptDescriptions An array of prompt descriptions.\n   * @param promptTemplates An array of prompt templates.\n   * @param defaultChain An optional BaseChain instance to be used as the default chain.\n   * @param llmChainOpts Optional parameters for the LLMChainInput, excluding 'llm' and 'prompt'.\n   * @param conversationChainOpts Optional parameters for the LLMChainInput, excluding 'llm' and 'outputKey'.\n   * @param multiRouteChainOpts Optional parameters for the MultiRouteChainInput, excluding 'defaultChain'.\n   * @returns An instance of MultiPromptChain.\n   */\n  static fromLLMAndPrompts(\n    llm: BaseLanguageModelInterface,\n    {\n      promptNames,\n      promptDescriptions,\n      promptTemplates,\n      defaultChain,\n      llmChainOpts,\n      conversationChainOpts,\n      multiRouteChainOpts,\n    }: {\n      promptNames: string[];\n      promptDescriptions: string[];\n      promptTemplates: string[] | PromptTemplate[];\n      defaultChain?: BaseChain;\n      llmChainOpts?: Omit<LLMChainInput, \"llm\" | \"prompt\">;\n      conversationChainOpts?: Omit<LLMChainInput, \"llm\" | \"outputKey\">;\n      multiRouteChainOpts?: Omit<MultiRouteChainInput, \"defaultChain\">;\n    }\n  ): MultiPromptChain {\n    const destinations = zipEntries(promptNames, promptDescriptions).map(\n      ([name, desc]) => `${name}: ${desc}`\n    );\n\n    const structuredOutputParserSchema = z.object({\n      destination: z\n        .string()\n        .optional()\n        .describe('name of the question answering system to use or \"DEFAULT\"'),\n      next_inputs: z\n        .object({\n          input: z\n            .string()\n            .describe(\"a potentially modified version of the original input\"),\n        })\n        .describe(\"input to be fed to the next model\"),\n    });\n\n    const outputParser = new RouterOutputParser(structuredOutputParserSchema);\n\n    const destinationsStr = destinations.join(\"\\n\");\n    const routerTemplate = interpolateFString(\n      STRUCTURED_MULTI_PROMPT_ROUTER_TEMPLATE(\n        outputParser.getFormatInstructions({ interpolationDepth: 4 })\n      ),\n      {\n        destinations: destinationsStr,\n      }\n    );\n\n    const routerPrompt = new PromptTemplate({\n      template: routerTemplate,\n      inputVariables: [\"input\"],\n      outputParser,\n    });\n\n    const routerChain = LLMRouterChain.fromLLM(llm, routerPrompt);\n    const destinationChains = zipEntries<[string, string | PromptTemplate]>(\n      promptNames,\n      promptTemplates\n    ).reduce(\n      (acc, [name, template]) => {\n        let myPrompt: string | PromptTemplate;\n        if (typeof template === \"object\") {\n          myPrompt = template;\n        } else if (typeof template === \"string\") {\n          myPrompt = new PromptTemplate({\n            template: template as string,\n            inputVariables: [\"input\"],\n          });\n        } else {\n          throw new Error(\"Invalid prompt template\");\n        }\n        acc[name as string] = new LLMChain({\n          ...llmChainOpts,\n          llm,\n          prompt: myPrompt,\n        });\n        return acc;\n      },\n      {} as { [name: string]: LLMChain }\n    );\n\n    const convChain = new ConversationChain({\n      ...conversationChainOpts,\n      llm,\n      outputKey: \"text\",\n    });\n\n    return new MultiPromptChain({\n      ...multiRouteChainOpts,\n      routerChain,\n      destinationChains,\n      defaultChain: defaultChain ?? convChain,\n    });\n  }\n\n  _chainType(): string {\n    return \"multi_prompt_chain\";\n  }\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAuCA,IAAa,mBAAb,MAAa,yBAAyBA,oCAAgB;;;;CAIpD,OAAO,YACLC,KACAC,aACAC,oBACAC,iBACAC,cACAC,SACA;AACA,SAAO,iBAAiB,kBAAkB,KAAK;GAC7C;GACA;GACA;GACA;GACA,qBAAqB;EACtB,EAAC;CACH;;;;;;;;;;;;;;;CAgBD,OAAO,kBACLL,KACA,EACE,aACA,oBACA,iBACA,cACA,cACA,uBACA,qBASD,EACiB;EAClB,MAAM,eAAeM,yBAAW,aAAa,mBAAmB,CAAC,IAC/D,CAAC,CAAC,MAAM,KAAK,KAAK,GAAG,KAAK,EAAE,EAAE,MAAM,CACrC;EAED,MAAM,+BAA+BC,SAAE,OAAO;GAC5C,aAAaA,SACV,QAAQ,CACR,UAAU,CACV,SAAS,8DAA4D;GACxE,aAAaA,SACV,OAAO,EACN,OAAOA,SACJ,QAAQ,CACR,SAAS,uDAAuD,CACpE,EAAC,CACD,SAAS,oCAAoC;EACjD,EAAC;EAEF,MAAM,eAAe,IAAIC,kCAAmB;EAE5C,MAAM,kBAAkB,aAAa,KAAK,KAAK;EAC/C,MAAM,kEACJC,oEACE,aAAa,sBAAsB,EAAE,oBAAoB,EAAG,EAAC,CAC9D,EACD,EACE,cAAc,gBACf,EACF;EAED,MAAM,eAAe,IAAIC,wCAAe;GACtC,UAAU;GACV,gBAAgB,CAAC,OAAQ;GACzB;EACD;EAED,MAAM,cAAcC,kCAAe,QAAQ,KAAK,aAAa;EAC7D,MAAM,oBAAoBL,yBACxB,aACA,gBACD,CAAC,OACA,CAAC,KAAK,CAAC,MAAM,SAAS,KAAK;GACzB,IAAIM;AACJ,OAAI,OAAO,aAAa,UACtB,WAAW;YACF,OAAO,aAAa,UAC7B,WAAW,IAAIF,wCAAe;IAClB;IACV,gBAAgB,CAAC,OAAQ;GAC1B;OAED,OAAM,IAAI,MAAM;GAElB,IAAI,QAAkB,IAAIG,2BAAS;IACjC,GAAG;IACH;IACA,QAAQ;GACT;AACD,UAAO;EACR,GACD,CAAE,EACH;EAED,MAAM,YAAY,IAAIC,uCAAkB;GACtC,GAAG;GACH;GACA,WAAW;EACZ;AAED,SAAO,IAAI,iBAAiB;GAC1B,GAAG;GACH;GACA;GACA,cAAc,gBAAgB;EAC/B;CACF;CAED,aAAqB;AACnB,SAAO;CACR;AACF"}