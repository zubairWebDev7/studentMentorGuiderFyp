{"version":3,"file":"node.js","names":["a: string[]","b: string[]","idArray: string[]","ownerRepoCommit: string","options?: {\n    apiKey?: string;\n    apiUrl?: string;\n    includeModel?: boolean;\n    secrets?: Record<string, string>;\n    secretsFromEnv?: boolean;\n    client?: Client;\n    skipCache?: boolean;\n  }"],"sources":["../../src/hub/node.ts"],"sourcesContent":["import { Runnable } from \"@langchain/core/runnables\";\nimport type { Client } from \"langsmith\";\nimport {\n  basePull,\n  generateModelImportMap,\n  generateOptionalImportMap,\n  bindOutputSchema,\n} from \"./base.js\";\nimport { load } from \"../load/index.js\";\nimport { getChatModelByClassName } from \"../chat_models/universal.js\";\n\nexport { basePush as push } from \"./base.js\";\n\nfunction _idEquals(a: string[], b: string[]): boolean {\n  if (!Array.isArray(a) || !Array.isArray(b)) {\n    return false;\n  }\n  if (a.length !== b.length) {\n    return false;\n  }\n  for (let i = 0; i < a.length; i++) {\n    if (a[i] !== b[i]) {\n      return false;\n    }\n  }\n  return true;\n}\n\nfunction isRunnableBinding(a: string[]): boolean {\n  const wellKnownIds = [\n    [\"langchain_core\", \"runnables\", \"RunnableBinding\"],\n    [\"langchain\", \"schema\", \"runnable\", \"RunnableBinding\"],\n  ];\n  return wellKnownIds.some((id) => _idEquals(a, id));\n}\n\n/**\n * Infer modelProvider from the id namespace to avoid className collisions.\n * For non-langchain packages, extracts the provider name from the namespace.\n * e.g., [\"langchain\", \"chat_models\", \"vertexai\", \"ChatVertexAI\"] -> \"google-vertexai\"\n * e.g., [\"langchain_deepseek\", \"chat_models\", \"ChatDeepSeek\"] -> \"deepseek\"\n * @param idArray The full id array from the manifest\n * @returns The inferred modelProvider key or undefined\n */\nexport function inferModelProviderFromNamespace(\n  idArray: string[]\n): string | undefined {\n  if (!Array.isArray(idArray) || idArray.length < 2) {\n    return undefined;\n  }\n\n  // Check namespace parts (excluding the className at the end)\n  const namespace = idArray.slice(0, -1);\n\n  // Look for a part that looks like a provider package (not langchain/langchain_core)\n  for (const part of namespace) {\n    // Skip standard langchain packages\n    if (\n      part === \"langchain\" ||\n      part === \"langchain_core\" ||\n      part === \"chat_models\" ||\n      part === \"runnables\" ||\n      part === \"schema\"\n    ) {\n      continue;\n    }\n\n    // If it starts with \"langchain_\", extract the provider name\n    // e.g., \"langchain_google_genai\" -> \"google-genai\"\n    // e.g., \"langchain_deepseek\" -> \"deepseek\"\n    if (part.startsWith(\"langchain_\")) {\n      const providerName = part.slice(\"langchain_\".length);\n      // Convert underscores to hyphens to match MODEL_PROVIDER_CONFIG keys\n      return providerName.replace(/_/g, \"-\");\n    }\n\n    // Handle special cases for Google providers that need prefix\n    if (part.includes(\"vertexai_web\")) {\n      return \"google-vertexai-web\";\n    } else if (part.includes(\"vertexai\")) {\n      return \"google-vertexai\";\n    } else if (part.includes(\"genai\") || part.includes(\"google_genai\")) {\n      return \"google-genai\";\n    }\n\n    // For other provider-looking parts, use as-is with underscores converted to hyphens\n    // e.g., \"openai\" -> \"openai\", \"anthropic\" -> \"anthropic\"\n    if (\n      !part.includes(\"langchain\") &&\n      part !== \"chat_models\" &&\n      part !== \"runnables\"\n    ) {\n      return part.replace(/_/g, \"-\");\n    }\n  }\n\n  return undefined;\n}\n\n/**\n * Pull a prompt from the hub.\n * @param ownerRepoCommit The name of the repo containing the prompt, as well as an optional commit hash separated by a slash.\n * @param options.apiKey LangSmith API key to use when pulling the prompt\n * @param options.apiUrl LangSmith API URL to use when pulling the prompt\n * @param options.includeModel Whether to also instantiate and attach a model instance to the prompt,\n *   if the prompt has associated model metadata. If set to true, invoking the resulting pulled prompt will\n *   also invoke the instantiated model. You must have the appropriate LangChain integration package installed.\n * @param options.secrets A map of secrets to use when loading, e.g.\n *   {'OPENAI_API_KEY': 'sk-...'}`.\n *   If a secret is not found in the map, it will be loaded from the\n *   environment if `secrets_from_env` is `True`. Should only be needed when\n *   `includeModel` is `true`.\n * @param options.secretsFromEnv Whether to load secrets from environment variables.\n *   Use with caution and only with trusted prompts.\n * @param options.client LangSmith client to use when pulling the prompt\n * @param options.skipCache Whether to skip the global default cache when pulling the prompt\n * @returns\n */\nexport async function pull<T extends Runnable>(\n  ownerRepoCommit: string,\n  options?: {\n    apiKey?: string;\n    apiUrl?: string;\n    includeModel?: boolean;\n    secrets?: Record<string, string>;\n    secretsFromEnv?: boolean;\n    client?: Client;\n    skipCache?: boolean;\n  }\n) {\n  const promptObject = await basePull(ownerRepoCommit, options);\n  let modelClass;\n  if (options?.includeModel) {\n    const chatModelObject = isRunnableBinding(\n      promptObject.manifest.kwargs?.last?.id\n    )\n      ? promptObject.manifest.kwargs?.last?.kwargs?.bound\n      : promptObject.manifest.kwargs?.last;\n\n    if (Array.isArray(chatModelObject?.id)) {\n      const modelName = chatModelObject?.id.at(-1);\n\n      if (modelName) {\n        const modelProvider = inferModelProviderFromNamespace(\n          chatModelObject.id\n        );\n        modelClass = await getChatModelByClassName(modelName, modelProvider);\n        if (!modelClass) {\n          console.warn(\n            `Received unknown model name from prompt hub: \"${modelName}\"`\n          );\n        }\n      }\n    }\n  }\n  const loadedPrompt = await load<T>(\n    JSON.stringify(promptObject.manifest),\n    options?.secrets,\n    generateOptionalImportMap(modelClass),\n    generateModelImportMap(modelClass),\n    options?.secretsFromEnv\n  );\n  return bindOutputSchema(loadedPrompt);\n}\n"],"mappings":";;;;;AAaA,SAAS,UAAUA,GAAaC,GAAsB;AACpD,KAAI,CAAC,MAAM,QAAQ,EAAE,IAAI,CAAC,MAAM,QAAQ,EAAE,CACxC,QAAO;AAET,KAAI,EAAE,WAAW,EAAE,OACjB,QAAO;AAET,MAAK,IAAI,IAAI,GAAG,IAAI,EAAE,QAAQ,IAC5B,KAAI,EAAE,OAAO,EAAE,GACb,QAAO;AAGX,QAAO;AACR;AAED,SAAS,kBAAkBD,GAAsB;CAC/C,MAAM,eAAe,CACnB;EAAC;EAAkB;EAAa;CAAkB,GAClD;EAAC;EAAa;EAAU;EAAY;CAAkB,CACvD;AACD,QAAO,aAAa,KAAK,CAAC,OAAO,UAAU,GAAG,GAAG,CAAC;AACnD;;;;;;;;;AAUD,SAAgB,gCACdE,SACoB;AACpB,KAAI,CAAC,MAAM,QAAQ,QAAQ,IAAI,QAAQ,SAAS,EAC9C,QAAO;CAIT,MAAM,YAAY,QAAQ,MAAM,GAAG,GAAG;AAGtC,MAAK,MAAM,QAAQ,WAAW;AAE5B,MACE,SAAS,eACT,SAAS,oBACT,SAAS,iBACT,SAAS,eACT,SAAS,SAET;AAMF,MAAI,KAAK,WAAW,aAAa,EAAE;GACjC,MAAM,eAAe,KAAK,MAAM,GAAoB;AAEpD,UAAO,aAAa,QAAQ,MAAM,IAAI;EACvC;AAGD,MAAI,KAAK,SAAS,eAAe,CAC/B,QAAO;WACE,KAAK,SAAS,WAAW,CAClC,QAAO;WACE,KAAK,SAAS,QAAQ,IAAI,KAAK,SAAS,eAAe,CAChE,QAAO;AAKT,MACE,CAAC,KAAK,SAAS,YAAY,IAC3B,SAAS,iBACT,SAAS,YAET,QAAO,KAAK,QAAQ,MAAM,IAAI;CAEjC;AAED,QAAO;AACR;;;;;;;;;;;;;;;;;;;;AAqBD,eAAsB,KACpBC,iBACAC,SASA;CACA,MAAM,eAAe,MAAM,SAAS,iBAAiB,QAAQ;CAC7D,IAAI;AACJ,KAAI,SAAS,cAAc;EACzB,MAAM,kBAAkB,kBACtB,aAAa,SAAS,QAAQ,MAAM,GACrC,GACG,aAAa,SAAS,QAAQ,MAAM,QAAQ,QAC5C,aAAa,SAAS,QAAQ;AAElC,MAAI,MAAM,QAAQ,iBAAiB,GAAG,EAAE;GACtC,MAAM,YAAY,iBAAiB,GAAG,GAAG,GAAG;AAE5C,OAAI,WAAW;IACb,MAAM,gBAAgB,gCACpB,gBAAgB,GACjB;IACD,aAAa,MAAM,wBAAwB,WAAW,cAAc;AACpE,QAAI,CAAC,YACH,QAAQ,KACN,CAAC,8CAA8C,EAAE,UAAU,CAAC,CAAC,CAC9D;GAEJ;EACF;CACF;CACD,MAAM,eAAe,MAAM,KACzB,KAAK,UAAU,aAAa,SAAS,EACrC,SAAS,SACT,0BAA0B,WAAW,EACrC,uBAAuB,WAAW,EAClC,SAAS,eACV;AACD,QAAO,iBAAiB,aAAa;AACtC"}